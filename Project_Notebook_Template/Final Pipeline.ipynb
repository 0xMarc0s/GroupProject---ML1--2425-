{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad09b7f8",
   "metadata": {
    "id": "ad09b7f8"
   },
   "source": [
    "<b><font size=\"6\">Predictive Modelling Pipeline Template</font></b><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253d4d8",
   "metadata": {
    "id": "7253d4d8"
   },
   "source": [
    "In this notebook we present to you the main steps you should follow throughout your project.\n",
    "\n",
    "\n",
    "<b> Important: The numbered sections and subsections are merely indicative of some of the steps you should pay attention to in your project. <br>You are not required to strictly follow this order or to execute everything in separate cells.</b>\n",
    "    \n",
    "<img src=\"image/process_ML.png\" style=\"height:70px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b51dd532",
   "metadata": {
    "id": "b51dd532"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18852571",
   "metadata": {
    "id": "18852571"
   },
   "source": [
    "<a class=\"anchor\" id=\"\">\n",
    "\n",
    "# 1. Import data (Data Integration)\n",
    "\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaea6ca",
   "metadata": {
    "id": "2eaea6ca"
   },
   "source": [
    "<img src=\"image/step1.png\" style=\"height:60px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "nqPU0XFheKHi",
   "metadata": {
    "id": "nqPU0XFheKHi"
   },
   "outputs": [],
   "source": [
    "# Load the data in a simple way\n",
    "obesity_train_raw = pd.read_csv('../data/obesity_train.csv')\n",
    "obesity_test_raw = pd.read_csv('../data/obesity_test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "54a29bcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729597252855,
     "user": {
      "displayName": "Michał Wójcik",
      "userId": "08591631202502653658"
     },
     "user_tz": -60
    },
    "id": "54a29bcb",
    "outputId": "eff7a2d5-4ce8-42c5-80cd-0781efa37051"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_freq</th>\n",
       "      <th>caloric_freq</th>\n",
       "      <th>devices_perday</th>\n",
       "      <th>eat_between_meals</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>marrital_status</th>\n",
       "      <th>meals_perday</th>\n",
       "      <th>...</th>\n",
       "      <th>parent_overweight</th>\n",
       "      <th>physical_activity_perweek</th>\n",
       "      <th>region</th>\n",
       "      <th>siblings</th>\n",
       "      <th>smoke</th>\n",
       "      <th>transportation</th>\n",
       "      <th>veggies_freq</th>\n",
       "      <th>water_daily</th>\n",
       "      <th>weight</th>\n",
       "      <th>obese_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Never</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Walk</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>5 or more</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>more than 2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Car</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>less than 1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age alcohol_freq caloric_freq devices_perday eat_between_meals  \\\n",
       "0   1  21.0        Never           no        up to 5         Sometimes   \n",
       "1   2  23.0   Frequently           no        up to 5         Sometimes   \n",
       "2   3   NaN   Frequently           no        up to 2         Sometimes   \n",
       "3   4  22.0    Sometimes           no        up to 2         Sometimes   \n",
       "4   5  22.0    Sometimes           no        up to 2         Sometimes   \n",
       "5   6  24.0   Frequently          yes        up to 5         Sometimes   \n",
       "6   7  21.0    Sometimes          yes        up to 5        Frequently   \n",
       "7   8  22.0    Sometimes           no        up to 2         Sometimes   \n",
       "8   9  41.0   Frequently          yes        up to 5         Sometimes   \n",
       "9  10  27.0    Sometimes          yes        up to 2         Sometimes   \n",
       "\n",
       "   gender  height  marrital_status  meals_perday  ... parent_overweight  \\\n",
       "0  Female    1.62              NaN           3.0  ...               yes   \n",
       "1    Male    1.80              NaN           3.0  ...               yes   \n",
       "2    Male    1.80              NaN           3.0  ...                no   \n",
       "3    Male    1.78              NaN           1.0  ...                no   \n",
       "4    Male    1.64              NaN           3.0  ...                no   \n",
       "5    Male    1.78              NaN           3.0  ...               yes   \n",
       "6  Female    1.72              NaN           3.0  ...               yes   \n",
       "7    Male    1.65              NaN           3.0  ...                no   \n",
       "8    Male    1.80              NaN           3.0  ...                no   \n",
       "9    Male    1.93              NaN           1.0  ...               yes   \n",
       "\n",
       "  physical_activity_perweek region siblings  smoke transportation  \\\n",
       "0                       NaN  LatAm      3.0     no         Public   \n",
       "1                    3 to 4  LatAm      0.0     no         Public   \n",
       "2                    3 to 4  LatAm      2.0     no           Walk   \n",
       "3                       NaN  LatAm      3.0     no         Public   \n",
       "4                 5 or more  LatAm      3.0     no         Public   \n",
       "5                    1 to 2  LatAm      2.0     no         Public   \n",
       "6                    3 to 4    NaN      2.0     no         Public   \n",
       "7                    3 to 4  LatAm      1.0     no         Public   \n",
       "8                    3 to 4  LatAm      0.0     no            Car   \n",
       "9                    1 to 2  LatAm      2.0     no         Public   \n",
       "\n",
       "  veggies_freq  water_daily weight          obese_level  \n",
       "0    Sometimes       1 to 2   64.0        Normal_Weight  \n",
       "1    Sometimes       1 to 2   77.0        Normal_Weight  \n",
       "2       Always       1 to 2   87.0   Overweight_Level_I  \n",
       "3    Sometimes       1 to 2   90.0  Overweight_Level_II  \n",
       "4    Sometimes       1 to 2   53.0        Normal_Weight  \n",
       "5       Always       1 to 2   64.0        Normal_Weight  \n",
       "6    Sometimes       1 to 2   80.0  Overweight_Level_II  \n",
       "7       Always  more than 2   56.0        Normal_Weight  \n",
       "8    Sometimes       1 to 2   99.0       Obesity_Type_I  \n",
       "9    Sometimes  less than 1  102.0  Overweight_Level_II  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_train_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ffee8f19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1729597253173,
     "user": {
      "displayName": "Michał Wójcik",
      "userId": "08591631202502653658"
     },
     "user_tz": -60
    },
    "id": "ffee8f19",
    "outputId": "22ed1cf5-de0d-4ad1-c554-7f49672fcb9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_freq</th>\n",
       "      <th>caloric_freq</th>\n",
       "      <th>devices_perday</th>\n",
       "      <th>eat_between_meals</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>marrital_status</th>\n",
       "      <th>meals_perday</th>\n",
       "      <th>monitor_calories</th>\n",
       "      <th>parent_overweight</th>\n",
       "      <th>physical_activity_perweek</th>\n",
       "      <th>region</th>\n",
       "      <th>siblings</th>\n",
       "      <th>smoke</th>\n",
       "      <th>transportation</th>\n",
       "      <th>veggies_freq</th>\n",
       "      <th>water_daily</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1612</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>5 or more</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>more than 2</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1613</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Car</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1614</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1615</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Never</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1616</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>more than 2</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1617</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>less than 1</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1618</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Always</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1619</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Never</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Car</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1620</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Never</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Car</td>\n",
       "      <td>Always</td>\n",
       "      <td>less than 1</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1621</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Car</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   age alcohol_freq caloric_freq devices_perday eat_between_meals  \\\n",
       "0  1612  21.0    Sometimes           no        up to 2         Sometimes   \n",
       "1  1613  29.0    Sometimes          yes        up to 2         Sometimes   \n",
       "2  1614  23.0    Sometimes          NaN        up to 2         Sometimes   \n",
       "3  1615  22.0        Never          yes        up to 5         Sometimes   \n",
       "4  1616  26.0    Sometimes          yes    more than 5        Frequently   \n",
       "5  1617  23.0    Sometimes          yes        up to 5         Sometimes   \n",
       "6  1618  22.0    Sometimes           no        up to 5            Always   \n",
       "7  1619  29.0        Never          yes        up to 2         Sometimes   \n",
       "8  1620  30.0        Never          yes        up to 2        Frequently   \n",
       "9  1621  23.0    Sometimes          yes        up to 5        Frequently   \n",
       "\n",
       "   gender  height  marrital_status  meals_perday monitor_calories  \\\n",
       "0  Female    1.52              NaN           3.0              yes   \n",
       "1    Male    1.62              NaN           3.0               no   \n",
       "2  Female    1.50              NaN           3.0               no   \n",
       "3    Male    1.72              NaN           3.0               no   \n",
       "4    Male    1.85              NaN           3.0               no   \n",
       "5    Male    1.77              NaN           1.0               no   \n",
       "6  Female    1.70              NaN           3.0              yes   \n",
       "7  Female    1.53              NaN           1.0               no   \n",
       "8  Female    1.71              NaN           4.0               no   \n",
       "9  Female    1.60              NaN           4.0               no   \n",
       "\n",
       "  parent_overweight physical_activity_perweek region  siblings smoke  \\\n",
       "0               yes                 5 or more  LatAm       3.0   yes   \n",
       "1                no                       NaN  LatAm       3.0    no   \n",
       "2               yes                    1 to 2  LatAm       2.0    no   \n",
       "3               yes                    1 to 2  LatAm       1.0    no   \n",
       "4               yes                    3 to 4  LatAm       1.0    no   \n",
       "5               yes                    1 to 2  LatAm       2.0    no   \n",
       "6               yes                    3 to 4  LatAm       1.0    no   \n",
       "7                no                       NaN  LatAm       0.0    no   \n",
       "8               yes                       NaN  LatAm       0.0   yes   \n",
       "9                no                    3 to 4  LatAm       3.0    no   \n",
       "\n",
       "  transportation veggies_freq  water_daily  weight  \n",
       "0         Public       Always  more than 2    56.0  \n",
       "1            Car    Sometimes       1 to 2    53.0  \n",
       "2      Motorbike       Always       1 to 2     NaN  \n",
       "3         Public    Sometimes       1 to 2    68.0  \n",
       "4         Public       Always  more than 2   105.0  \n",
       "5         Public       Always  less than 1    60.0  \n",
       "6         Public       Always       1 to 2     NaN  \n",
       "7            Car    Sometimes       1 to 2    78.0  \n",
       "8            Car       Always  less than 1    82.0  \n",
       "9            Car    Sometimes       1 to 2    52.0  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_test_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d2690",
   "metadata": {
    "id": "2f5d2690"
   },
   "source": [
    "<a class=\"anchor\" id=\"\">\n",
    "\n",
    "# 2. Explore data (Data access, exploration and understanding)\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dcd9d4",
   "metadata": {
    "id": "a4dcd9d4"
   },
   "source": [
    "<img src=\"image/step2.png\" style=\"height:60px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae9956",
   "metadata": {
    "id": "d7ae9956"
   },
   "source": [
    "Remember, this step is very important as it is at this stage that you will really look into the data that you have. Generally speaking, if you do well at this stage, the following stages will be very smooth.\n",
    "\n",
    "Moreover, you should also take the time to find meaningful patterns on the data: what interesting relationships can be found between the variables and how can that knowledge be inform your future decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "acae7518",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1729597253173,
     "user": {
      "displayName": "Michał Wójcik",
      "userId": "08591631202502653658"
     },
     "user_tz": -60
    },
    "id": "acae7518",
    "outputId": "457f0ab6-1fed-4b5a-fede-ba27e9337c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1611 entries, 0 to 1610\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         1611 non-null   int64  \n",
      " 1   age                        1545 non-null   float64\n",
      " 2   alcohol_freq               1575 non-null   object \n",
      " 3   caloric_freq               1591 non-null   object \n",
      " 4   devices_perday             1589 non-null   object \n",
      " 5   eat_between_meals          1552 non-null   object \n",
      " 6   gender                     1591 non-null   object \n",
      " 7   height                     1597 non-null   float64\n",
      " 8   marrital_status            0 non-null      float64\n",
      " 9   meals_perday               1602 non-null   float64\n",
      " 10  monitor_calories           1572 non-null   object \n",
      " 11  parent_overweight          1591 non-null   object \n",
      " 12  physical_activity_perweek  1046 non-null   object \n",
      " 13  region                     1544 non-null   object \n",
      " 14  siblings                   1599 non-null   float64\n",
      " 15  smoke                      1599 non-null   object \n",
      " 16  transportation             1571 non-null   object \n",
      " 17  veggies_freq               1585 non-null   object \n",
      " 18  water_daily                1577 non-null   object \n",
      " 19  weight                     1558 non-null   float64\n",
      " 20  obese_level                1611 non-null   object \n",
      "dtypes: float64(6), int64(1), object(14)\n",
      "memory usage: 264.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display information about the training dataset\n",
    "obesity_train_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186631e",
   "metadata": {
    "id": "1186631e"
   },
   "source": [
    "<a class=\"anchor\" id=\"\">\n",
    "\n",
    "# 3. Modify data (Data preparation)\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01adeef2",
   "metadata": {
    "id": "01adeef2"
   },
   "source": [
    "<img src=\"image/step3.png\" style=\"height:60px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12772f7",
   "metadata": {
    "id": "d12772f7"
   },
   "source": [
    "Use this section to apply transformations to your dataset.\n",
    "\n",
    "Remember that your decisions at this step should be exclusively informed by your **training data**. While you will need to split your data between training and validation, how that split will be made and how to apply the approppriate transformations will depend on the type of model assessment solution you select for your project (each has its own set of advantages and disadvantages that you need to consider). **Please find a list of possible methods for model assessment below**:\n",
    "\n",
    "1. **Holdout method**\n",
    "2. **Repeated Holdout method**\n",
    "3. **Cross-Validation**\n",
    "\n",
    "__Note:__ Instead of creating different sections for the treatment of training and validation data, you can make the transformations in the same cell. There is no need to create a specific section for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6b621",
   "metadata": {
    "id": "eff6b621"
   },
   "source": [
    "### 3.1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "238c088d",
   "metadata": {
    "id": "238c088d"
   },
   "outputs": [],
   "source": [
    "# Drop the 'marrital_status' and 'region' columns from the dataset\n",
    "obesity_train = obesity_train_raw.drop(columns=['marrital_status', 'region'])\n",
    "obesity_test = obesity_test_raw.drop(columns=['marrital_status', 'region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "Xfez5_d4e70T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1729608382028,
     "user": {
      "displayName": "Skeletal",
      "userId": "03029484600494071692"
     },
     "user_tz": -60
    },
    "id": "Xfez5_d4e70T",
    "outputId": "291b2dda-d1c9-4e6d-f082-92997666448a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_freq</th>\n",
       "      <th>caloric_freq</th>\n",
       "      <th>devices_perday</th>\n",
       "      <th>eat_between_meals</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>meals_perday</th>\n",
       "      <th>monitor_calories</th>\n",
       "      <th>parent_overweight</th>\n",
       "      <th>physical_activity_perweek</th>\n",
       "      <th>siblings</th>\n",
       "      <th>smoke</th>\n",
       "      <th>transportation</th>\n",
       "      <th>veggies_freq</th>\n",
       "      <th>water_daily</th>\n",
       "      <th>weight</th>\n",
       "      <th>obese_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Never</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Walk</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.64</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>5 or more</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>131.0</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>134.0</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>134.0</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>more than 2</td>\n",
       "      <td>133.0</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>more than 2</td>\n",
       "      <td>133.0</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1611 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age alcohol_freq caloric_freq devices_perday eat_between_meals  gender  \\\n",
       "id                                                                              \n",
       "1     21.0        Never           no        up to 5         Sometimes  Female   \n",
       "2     23.0   Frequently           no        up to 5         Sometimes    Male   \n",
       "3      NaN   Frequently           no        up to 2         Sometimes    Male   \n",
       "4     22.0    Sometimes           no        up to 2         Sometimes    Male   \n",
       "5     22.0    Sometimes           no        up to 2         Sometimes    Male   \n",
       "...    ...          ...          ...            ...               ...     ...   \n",
       "1607  21.0    Sometimes          NaN        up to 5         Sometimes  Female   \n",
       "1608  22.0    Sometimes          yes        up to 5         Sometimes  Female   \n",
       "1609  23.0    Sometimes          yes        up to 5         Sometimes  Female   \n",
       "1610  24.0    Sometimes          yes        up to 5         Sometimes  Female   \n",
       "1611  24.0    Sometimes          yes        up to 5         Sometimes  Female   \n",
       "\n",
       "      height  meals_perday monitor_calories parent_overweight  \\\n",
       "id                                                              \n",
       "1       1.62           3.0               no               yes   \n",
       "2       1.80           3.0               no               yes   \n",
       "3       1.80           3.0               no                no   \n",
       "4       1.78           1.0               no                no   \n",
       "5       1.64           3.0               no                no   \n",
       "...      ...           ...              ...               ...   \n",
       "1607    1.73           3.0               no               yes   \n",
       "1608    1.75           3.0               no               yes   \n",
       "1609    1.75           3.0               no               yes   \n",
       "1610    1.74           3.0               no               yes   \n",
       "1611    1.74           3.0               no               yes   \n",
       "\n",
       "     physical_activity_perweek  siblings smoke transportation veggies_freq  \\\n",
       "id                                                                           \n",
       "1                          NaN       3.0    no         Public    Sometimes   \n",
       "2                       3 to 4       0.0    no         Public    Sometimes   \n",
       "3                       3 to 4       2.0    no           Walk       Always   \n",
       "4                          NaN       3.0    no         Public    Sometimes   \n",
       "5                    5 or more       3.0    no         Public    Sometimes   \n",
       "...                        ...       ...   ...            ...          ...   \n",
       "1607                    3 to 4       1.0    no         Public       Always   \n",
       "1608                    1 to 2       0.0    no            NaN       Always   \n",
       "1609                    1 to 2       0.0    no         Public       Always   \n",
       "1610                    1 to 2       0.0    no         Public       Always   \n",
       "1611                    1 to 2       0.0    no         Public       Always   \n",
       "\n",
       "      water_daily  weight          obese_level  \n",
       "id                                              \n",
       "1          1 to 2    64.0        Normal_Weight  \n",
       "2          1 to 2    77.0        Normal_Weight  \n",
       "3          1 to 2    87.0   Overweight_Level_I  \n",
       "4          1 to 2    90.0  Overweight_Level_II  \n",
       "5          1 to 2    53.0        Normal_Weight  \n",
       "...           ...     ...                  ...  \n",
       "1607       1 to 2   131.0     Obesity_Type_III  \n",
       "1608       1 to 2   134.0     Obesity_Type_III  \n",
       "1609       1 to 2   134.0     Obesity_Type_III  \n",
       "1610  more than 2   133.0     Obesity_Type_III  \n",
       "1611  more than 2   133.0     Obesity_Type_III  \n",
       "\n",
       "[1611 rows x 18 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_train.set_index('id', inplace=True)\n",
    "obesity_test.set_index('id', inplace=True)\n",
    "obesity_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7rfkILCKkbzS",
   "metadata": {
    "id": "7rfkILCKkbzS"
   },
   "outputs": [],
   "source": [
    "# Selecting outliers for which the age is out of scope. Or the weight classification is suspiciously low for the value given\n",
    "outliers = obesity_train[\n",
    "    ((obesity_train['age'] < 16) & ~(obesity_train['age'].isna())) |\n",
    "    ((obesity_train['age'] > 56) & ~(obesity_train['age'].isna())) |\n",
    "    ((obesity_train['weight'] > 167) & ~(obesity_train['weight'].isna()))\n",
    "]\n",
    "obesity_train.drop(outliers.index, inplace=True)\n",
    "obesity_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "gz9nal_KPUGu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1729608389845,
     "user": {
      "displayName": "Skeletal",
      "userId": "03029484600494071692"
     },
     "user_tz": -60
    },
    "id": "gz9nal_KPUGu",
    "outputId": "e4946bf0-1b24-4a80-9c85-68be30f0295c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1605, 18)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_train.shape # Shape adds up to our expectation (6 rows deleted) 1611 -> 1605 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813e2d3",
   "metadata": {},
   "source": [
    "# Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6f636105",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = obesity_train.select_dtypes(include='object').columns\n",
    "numerical_columns = obesity_train.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ab7f7048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'alcohol_freq', 'caloric_freq', 'devices_perday',\n",
       "       'eat_between_meals', 'gender', 'height', 'meals_perday',\n",
       "       'monitor_calories', 'parent_overweight', 'physical_activity_perweek',\n",
       "       'siblings', 'smoke', 'transportation', 'veggies_freq', 'water_daily',\n",
       "       'weight', 'obese_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d80d9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashmap = {\n",
    "\"Never\": 0,\n",
    "\"Sometimes\": 1,\n",
    "\"Frequently\": 2,\n",
    "\"Always\": 3,\n",
    "\n",
    "\"No Activity\": 0,\n",
    "\"up to 2\": 1,\n",
    "\"up to 5\": 2,\n",
    "\"more than 5\": 3,\n",
    "\n",
    "\"less than 1\": 1,\n",
    "\"1 to 2\": 2,\n",
    "\"more than 2\": 3,\n",
    "\"3 to 4\": 4,\n",
    "\"5 or more\": 5,\n",
    "\n",
    "\"Bicycle\": 1,\n",
    "\"Car\": 3,\n",
    "\"Motorbike\": 3,\n",
    "\"Public\": 2,\n",
    "\"Walk\": 0,\n",
    "\n",
    "\"no\": 0,\n",
    "\"yes\": 1,\n",
    "\n",
    "\"Male\": 0,\n",
    "\"Female\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6c59ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually encode data\n",
    "\n",
    "columns = ['alcohol_freq',\n",
    " 'caloric_freq',\n",
    " 'devices_perday',\n",
    " 'eat_between_meals',\n",
    " 'gender',\n",
    " 'monitor_calories',\n",
    " 'parent_overweight',\n",
    " 'physical_activity_perweek',\n",
    " 'smoke',\n",
    " 'transportation',\n",
    " 'veggies_freq',\n",
    " 'water_daily',\n",
    " 'meals_perday',\n",
    " \"siblings\"]\n",
    "\n",
    "for target in columns:\n",
    "    obesity_train[target] = obesity_train[target].replace(hashmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "90872b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                           65\n",
       "alcohol_freq                  36\n",
       "caloric_freq                  20\n",
       "devices_perday                21\n",
       "eat_between_meals             59\n",
       "gender                        20\n",
       "height                        13\n",
       "meals_perday                   9\n",
       "monitor_calories              39\n",
       "parent_overweight             20\n",
       "physical_activity_perweek    564\n",
       "siblings                      12\n",
       "smoke                         12\n",
       "transportation                40\n",
       "veggies_freq                  26\n",
       "water_daily                   34\n",
       "weight                        53\n",
       "obese_level                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_train_encoded = obesity_train.copy()\n",
    "obesity_train_encoded.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0QWZatS0_nup",
   "metadata": {
    "id": "0QWZatS0_nup"
   },
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "93887093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with mode and median as the first null-handling resolution. Will be re-approached with further iterations on the model itself\n",
    "\n",
    "obesity_train_encoded['physical_activity_perweek'].fillna(0, inplace=True) # ASSUMPTION: There is no 0 value in the scope. We assume nulls are the people who dont work out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7188d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = obesity_train_encoded.drop(columns='obese_level')\n",
    "y = obesity_train_encoded[['obese_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "Bs2-yQrj-2MO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1729597253173,
     "user": {
      "displayName": "Michał Wójcik",
      "userId": "08591631202502653658"
     },
     "user_tz": -60
    },
    "id": "Bs2-yQrj-2MO",
    "outputId": "175cf935-ac35-4b93-dc15-4991acc43e03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          65\n",
       "alcohol_freq                 36\n",
       "caloric_freq                 20\n",
       "devices_perday               21\n",
       "eat_between_meals            59\n",
       "gender                       20\n",
       "height                       13\n",
       "meals_perday                  9\n",
       "monitor_calories             39\n",
       "parent_overweight            20\n",
       "physical_activity_perweek     0\n",
       "siblings                     12\n",
       "smoke                        12\n",
       "transportation               40\n",
       "veggies_freq                 26\n",
       "water_daily                  34\n",
       "weight                       53\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2516007f",
   "metadata": {},
   "source": [
    "# Original imputing function\n",
    "\n",
    "\n",
    "\n",
    "data_knnimputer_train = X.copy()\n",
    "\n",
    "numerical_columns_features = numerical_columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_knnimputer_train[numerical_columns_features] = scaler.fit_transform(data_knnimputer_train[numerical_columns_features])\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "data_knnimputer_train[numerical_columns_features] = knn_imputer.fit_transform(data_knnimputer_train[numerical_columns_features])\n",
    "\n",
    "data_knnimputer_train[numerical_columns_features] = scaler.inverse_transform(data_knnimputer_train[numerical_columns_features])\n",
    "\n",
    "print(data_knnimputer_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ed988027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def knn_impute(X_train, X_val, numerical_columns, n_neighbors=5):\n",
    "\n",
    "    # Create copies for KNN imputation\n",
    "    data_knnimputer_train = X_train.copy()\n",
    "    data_knnimputer_val = X_val.copy()\n",
    "\n",
    "    # Specify the columns to scale\n",
    "    numerical_columns_features = numerical_columns\n",
    "\n",
    "    # Scale the data for KNN imputation\n",
    "    scaler = StandardScaler()\n",
    "    data_knnimputer_train[numerical_columns_features] = scaler.fit_transform(data_knnimputer_train[numerical_columns_features])\n",
    "    data_knnimputer_val[numerical_columns_features] = scaler.transform(data_knnimputer_val[numerical_columns_features])\n",
    "\n",
    "    # Perform KNN imputation\n",
    "    knn_imputer = KNNImputer(n_neighbors=n_neighbors, weights='uniform')\n",
    "    data_knnimputer_train[numerical_columns_features] = knn_imputer.fit_transform(data_knnimputer_train[numerical_columns_features])\n",
    "    data_knnimputer_val[numerical_columns_features] = knn_imputer.transform(data_knnimputer_val[numerical_columns_features])\n",
    "\n",
    "    # Inverse transform to original scale\n",
    "    data_knnimputer_train[numerical_columns_features] = scaler.inverse_transform(data_knnimputer_train[numerical_columns_features])\n",
    "    data_knnimputer_val[numerical_columns_features] = scaler.inverse_transform(data_knnimputer_val[numerical_columns_features])\n",
    "\n",
    "    return data_knnimputer_train, data_knnimputer_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6a925",
   "metadata": {},
   "source": [
    "Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "KwdC5nPyxzt4",
   "metadata": {
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1729609910202,
     "user": {
      "displayName": "Michał Wójcik",
      "userId": "08591631202502653658"
     },
     "user_tz": -60
    },
    "id": "KwdC5nPyxzt4"
   },
   "outputs": [],
   "source": [
    "def classify_bmi_comprehensive(row):\n",
    "    \"\"\"\n",
    "    Classify BMI based on age and BMI value.\n",
    "\n",
    "    Input:\n",
    "    row: A Pandas row with 'weight', 'height', and 'age' columns.\n",
    "\n",
    "    Output:\n",
    "    Returns a string that classifies the individual into BMI categories.\n",
    "    \"\"\"\n",
    "    # Check if weight and height are valid\n",
    "    if row['height'] <= 0 or row['weight'] <= 0:\n",
    "        return 'Invalid data'\n",
    "\n",
    "    # Calculate BMI\n",
    "    bmi = row['weight'] / (row['height'] ** 2)\n",
    "\n",
    "    # Age group: Children (2-19 years)\n",
    "    if 2 <= row['age'] < 20:\n",
    "        if bmi < 14:\n",
    "            return 0 # Underweight\n",
    "        elif 14 <= bmi < 18:\n",
    "            return 1 # Normal weight\n",
    "        elif 18 <= bmi < 21:\n",
    "            return 2 # Overweight\n",
    "        else:\n",
    "            return 3 # Obesity 1\n",
    "\n",
    "    # Age group: Adults (20-64 years)\n",
    "    elif 20 <= row['age'] < 65:\n",
    "        if bmi < 18.5:\n",
    "            return 0 # \"Underweight\"\n",
    "        elif 18.5 <= bmi < 25:\n",
    "            return 1 # \"Healthy Weight\"\n",
    "        elif 25 <= bmi < 30:\n",
    "            return 2 #\"Overweight\"\n",
    "        elif 30<= bmi < 35:\n",
    "            return 3 #\"Obese Class 1\"\n",
    "        elif 35 <= bmi < 40:\n",
    "            return 4 #\"Obese Class 2\"\n",
    "        else:\n",
    "            return 5 #\"Obese Class 3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e026ec",
   "metadata": {},
   "source": [
    "# Manually encode the obesity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "681afb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_obesity = {\n",
    " 'Normal_Weight': 1,\n",
    " 'Overweight_Level_I': 2,\n",
    " 'Overweight_Level_II': 3,\n",
    " 'Obesity_Type_I': 4,\n",
    " 'Insufficient_Weight': 5,\n",
    " 'Obesity_Type_II': 6,\n",
    " 'Obesity_Type_III': 7\n",
    " }\n",
    "\n",
    "y = y['obese_level'].replace(hash_obesity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67a6917",
   "metadata": {},
   "source": [
    "Impute categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d8ea9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IterativeImputer with KNeighborsClassifier for categorical data imputation\n",
    "#iterative_imputer = IterativeImputer(estimator=KNeighborsClassifier(n_neighbors=5), max_iter=10, random_state=42, \n",
    "#                                     skip_complete=True)\n",
    "\n",
    "# Perform imputation on the encoded categorical data\n",
    "#data_knnimputer_train_imputed = iterative_imputer.fit_transform(data_knnimputer_train)\n",
    "\n",
    "# Convert back to DataFrame and assign original column names\n",
    "#data_knnimputer_train = pd.DataFrame(data_knnimputer_train_imputed, columns=data_knnimputer_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ef152e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # Enable IterativeImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize IterativeImputer with KNeighborsClassifier for categorical data imputation\n",
    "#iterative_imputer = IterativeImputer(estimator=KNeighborsClassifier(n_neighbors=5), max_iter=10, random_state=42, \n",
    "#                                     skip_complete=True)\n",
    "\n",
    "# Perform imputation on the encoded categorical data\n",
    "#data_knnimputer_train_imputed = iterative_imputer.fit_transform(data_knnimputer_train)\n",
    "\n",
    "# Convert back to DataFrame and assign original column names\n",
    "#data_knnimputer_train = pd.DataFrame(data_knnimputer_train_imputed, columns=data_knnimputer_train.columns)\n",
    "\n",
    "\n",
    "def iterative_impute(X_train, X_val, estimator=KNeighborsClassifier(n_neighbors=5), max_iter=10, random_state=42):\n",
    "    # Initialize IterativeImputer with the given estimator for categorical data imputation\n",
    "    iterative_imputer = IterativeImputer(estimator=estimator, max_iter=max_iter, random_state=random_state, skip_complete=True)\n",
    "    \n",
    "    # Perform imputation on the training and validation data\n",
    "    X_train_imputed = iterative_imputer.fit_transform(X_train)\n",
    "    X_val_imputed = iterative_imputer.transform(X_val)\n",
    "    \n",
    "    # Convert back to DataFrame and assign original column names\n",
    "    X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train.columns)\n",
    "    X_val_imputed = pd.DataFrame(X_val_imputed, columns=X_val.columns)\n",
    "    \n",
    "    return X_train_imputed, X_val_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0036efe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          65\n",
       "alcohol_freq                 36\n",
       "caloric_freq                 20\n",
       "devices_perday               21\n",
       "eat_between_meals            59\n",
       "gender                       20\n",
       "height                       13\n",
       "meals_perday                  9\n",
       "monitor_calories             39\n",
       "parent_overweight            20\n",
       "physical_activity_perweek     0\n",
       "siblings                     12\n",
       "smoke                        12\n",
       "transportation               40\n",
       "veggies_freq                 26\n",
       "water_daily                  34\n",
       "weight                       53\n",
       "dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "eea0f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to life score\n",
    "life_columns = [\n",
    " 'alcohol_freq',\n",
    " 'caloric_freq',\n",
    " 'devices_perday',\n",
    " 'eat_between_meals',\n",
    " 'monitor_calories',\n",
    " 'physical_activity_perweek',\n",
    " 'smoke',\n",
    " 'transportation',\n",
    " 'veggies_freq',\n",
    " 'water_daily',\n",
    " ]\n",
    "\n",
    "X[\"life\"] = 0\n",
    "\n",
    "for column in life_columns:\n",
    "    X[\"life\"] += X[column]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4de74",
   "metadata": {
    "id": "97a4de74"
   },
   "source": [
    "### 3.3. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478971ad",
   "metadata": {},
   "source": [
    "# Value scaling - finally done at the level of each fold so no prior scaling needed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale_age = StandardScaler().fit(encoded_train[[\"age\"]])\n",
    "scale_height = StandardScaler().fit(encoded_train[[\"height\"]])\n",
    "scale_weight = StandardScaler().fit(encoded_train[[\"weight\"]]) # Statistical analysis justifies the need to use RobustScaler on this one\n",
    "\n",
    "dfs = [encoded_train] # Transform both dataframes\n",
    "for df in dfs:\n",
    "    new_age = scale_age.transform(df[[\"age\"]])\n",
    "    new_height = scale_height.transform(df[[\"height\"]])\n",
    "    new_weight = scale_weight.transform(df[[\"weight\"]])\n",
    "\n",
    "    # Replace columns\n",
    "    df[\"age\"] = new_age\n",
    "    df[\"height\"] = new_height\n",
    "    df[\"weight\"] = new_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_scale = encoded_train.columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "encoded_train[columns_to_scale] = scaler.fit_transform(encoded_train[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee111e6e",
   "metadata": {
    "id": "ee111e6e"
   },
   "source": [
    "### 3.4. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "66c237cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.copy()\n",
    "y_train = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7f882da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.9396907630678435\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "tree = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Stratified K-Fold Cross Validation\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Impute missing values using KNN impute\n",
    "    X_train_fold, X_val_fold = knn_impute(X_train_fold, X_val_fold, numerical_columns)\n",
    "\n",
    "    # Classify BMI based on age and BMI value\n",
    "    X_train_fold['bmi_class'] = X_train_fold.apply(lambda row: classify_bmi_comprehensive(row), axis=1)\n",
    "    X_val_fold['bmi_class'] = X_val_fold.apply(lambda row: classify_bmi_comprehensive(row), axis=1)\n",
    "\n",
    "    # Impute missing values using Iterative impute\n",
    "    X_train_fold, X_val_fold = iterative_impute(X_train_fold, X_val_fold)\n",
    "    \n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler on the training fold and transform both training and validation folds\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "    \n",
    "    # Fit the model on the training fold\n",
    "    tree.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_pred_fold = tree.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_val_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print the average F1 score\n",
    "print(f\"Average F1 Score: {np.mean(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "68704670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.9454398972798019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "tree_gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Stratified K-Fold Cross Validation\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Impute missing values using KNN impute\n",
    "    X_train_fold, X_val_fold = knn_impute(X_train_fold, X_val_fold, numerical_columns)\n",
    "\n",
    "    # Classify BMI based on age and BMI value\n",
    "    X_train_fold['bmi_class'] = X_train_fold.apply(lambda row: classify_bmi_comprehensive(row), axis=1)\n",
    "    X_val_fold['bmi_class'] = X_val_fold.apply(lambda row: classify_bmi_comprehensive(row), axis=1)\n",
    "\n",
    "    # Impute missing values using Iterative impute\n",
    "    X_train_fold, X_val_fold = iterative_impute(X_train_fold, X_val_fold)\n",
    "\n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler on the training fold and transform both training and validation folds\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "\n",
    "    # Fit the model on the training fold\n",
    "    tree_gb.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_pred_fold = tree_gb.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_val_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print the average F1 score\n",
    "print(f\"Average F1 Score: {np.mean(f1_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be838ba",
   "metadata": {},
   "source": [
    "# RFE feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "871eccd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>0.339638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi_class</th>\n",
       "      <td>0.321481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.116929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.075033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol_freq</th>\n",
       "      <td>0.026831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat_between_meals</th>\n",
       "      <td>0.016908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caloric_freq</th>\n",
       "      <td>0.015403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transportation</th>\n",
       "      <td>0.006615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meals_perday</th>\n",
       "      <td>0.005404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>devices_perday</th>\n",
       "      <td>0.004681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veggies_freq</th>\n",
       "      <td>0.004154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.003236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent_overweight</th>\n",
       "      <td>0.003131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical_activity_perweek</th>\n",
       "      <td>0.002251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monitor_calories</th>\n",
       "      <td>0.001908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_daily</th>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siblings</th>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoke</th>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           importance\n",
       "weight                       0.339638\n",
       "bmi_class                    0.321481\n",
       "gender                       0.116929\n",
       "age                          0.075033\n",
       "height                       0.054200\n",
       "alcohol_freq                 0.026831\n",
       "eat_between_meals            0.016908\n",
       "caloric_freq                 0.015403\n",
       "transportation               0.006615\n",
       "meals_perday                 0.005404\n",
       "devices_perday               0.004681\n",
       "veggies_freq                 0.004154\n",
       "life                         0.003236\n",
       "parent_overweight            0.003131\n",
       "physical_activity_perweek    0.002251\n",
       "monitor_calories             0.001908\n",
       "water_daily                  0.001270\n",
       "siblings                     0.000590\n",
       "smoke                        0.000337"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = tree_gb.feature_importances_\n",
    "\n",
    "importances_df = pd.DataFrame(importances, index=X_train.columns, columns=['importance'])\n",
    "importances_df = importances_df.sort_values('importance', ascending=False)\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8a9d2c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[207], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     39\u001b[0m rfe \u001b[38;5;241m=\u001b[39m RFE(model, n_features_to_select\u001b[38;5;241m=\u001b[39mn)\n\u001b[1;32m---> 40\u001b[0m X_train_rfe \u001b[38;5;241m=\u001b[39m \u001b[43mrfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m X_val_rfe \u001b[38;5;241m=\u001b[39m rfe\u001b[38;5;241m.\u001b[39mtransform(X_val_fold)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Train and evaluate the model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\base.py:1101\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:268\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    267\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:323\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[1;32m--> 323\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    326\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    327\u001b[0m     estimator,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[0;32m    329\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    330\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "nof_list = np.arange(1, len(X_train.columns) + 2)\n",
    "high_score = float('-inf')\n",
    "nof = 0\n",
    "score_list = []\n",
    "best_features = None\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for n in tqdm(nof_list):\n",
    "    fold_scores = []\n",
    "    for train_index, val_index in skf.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        # Impute missing values using KNN impute\n",
    "        X_train_fold, X_val_fold = knn_impute(X_train_fold, X_val_fold, numerical_columns)\n",
    "\n",
    "        # Classify BMI based on age and BMI value\n",
    "        X_train_fold['bmi_class'] = X_train_fold.apply(classify_bmi_comprehensive, axis=1)\n",
    "        X_val_fold['bmi_class'] = X_val_fold.apply(classify_bmi_comprehensive, axis=1)\n",
    "\n",
    "        # Impute missing values using Iterative impute\n",
    "        X_train_fold, X_val_fold = iterative_impute(X_train_fold, X_val_fold)\n",
    "\n",
    "        # Scale the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Feature selection using RFE\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        rfe = RFE(model, n_features_to_select=n)\n",
    "        X_train_rfe = rfe.fit_transform(X_train_fold, y_train_fold)\n",
    "        X_val_rfe = rfe.transform(X_val_fold)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        model.fit(X_train_rfe, y_train_fold)\n",
    "        y_pred = model.predict(X_val_rfe)\n",
    "        score = f1_score(y_val_fold, y_pred, average='macro')\n",
    "        fold_scores.append(score)\n",
    "    \n",
    "    avg_score = np.mean(fold_scores)\n",
    "    score_list.append(avg_score)\n",
    "    \n",
    "    if avg_score > high_score:\n",
    "        high_score = avg_score\n",
    "        nof = n\n",
    "        best_features = rfe.get_support()\n",
    "\n",
    "print(f\"Optimum number of features: {nof}\")\n",
    "print(f\"Highest F1 score with {nof} features: {high_score:.6f}\")\n",
    "\n",
    "selected_feature_names = X_train.columns[best_features]\n",
    "print(f\"Selected features with {nof} features:\")\n",
    "print(selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fdd80d",
   "metadata": {},
   "source": [
    "# Exhaustive feature selection\n",
    "it is the one that tries every possibility so it runs soooo long but is the most accurate:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c51e4b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9309b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [04:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Combine the must-have features with other features and scale them in each fold to avoid leakage\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Track progress with tqdm\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mcolumns)) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Fit the feature selector on the dataset that includes both must-have and other features\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     efs \u001b[38;5;241m=\u001b[39m \u001b[43mefs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Get the best feature subset found by the selector, which includes combinations of other features and must-have features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\mlxtend\\feature_selection\\exhaustive_feature_selector.py:443\u001b[0m, in \u001b[0;36mExhaustiveFeatureSelector.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    440\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, all_comb)\n\u001b[0;32m    441\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, pre_dispatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch)\n\u001b[0;32m    442\u001b[0m work \u001b[38;5;241m=\u001b[39m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m--> 443\u001b[0m     \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_calc_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_features_group_set\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcandidates\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m )\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration, (indices, cv_scores) \u001b[38;5;129;01min\u001b[39;00m work:\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up the exhaustive feature selector, where 'other_features' will vary while 'must_have_features' remain\n",
    "efs = ExhaustiveFeatureSelector(\n",
    "    estimator=model,\n",
    "    min_features=6,  # Start with at least 6 features\n",
    "    max_features=len(X_train.columns),  # Consider up to all features\n",
    "    scoring='f1_macro',\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Combine the must-have features with other features and scale them in each fold to avoid leakage\n",
    "# Track progress with tqdm\n",
    "with tqdm(total=len(X_train.columns)) as progress_bar:\n",
    "    # Fit the feature selector on the dataset that includes both must-have and other features\n",
    "    efs = efs.fit(X_train, y_train)\n",
    "    progress_bar.update(len(X_train.columns))\n",
    "\n",
    "# Get the best feature subset found by the selector, which includes combinations of other features and must-have features\n",
    "selected_features = list(efs.best_feature_names_)\n",
    "\n",
    "# Perform cross-validation on the final selected features with scaling in each fold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in skf.split(X_train[final_features], y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index][final_features], X_train.iloc[val_index][final_features]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Initialize and fit the scaler only on the training data within each fold to avoid leakage\n",
    "    scaler = StandardScaler()\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Make predictions and calculate the F1 score\n",
    "    y_pred_fold = model.predict(X_val_fold)\n",
    "    f1 = f1_score(y_val_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average F1 Score after final evaluation: {np.mean(f1_scores)}\")\n",
    "print(\"Selected features including must-haves:\", final_features)\n",
    "print(\"Best F1 macro score from feature selection:\", efs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f964f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY NEEDED IF RFE WASNT RUN!!!\n",
    "best_selected_features_df = X_train#[selected_feature_names] # no smoke column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bdcc7",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1bcd9163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-11 15:59:24,342] A new study created in memory with name: no-name-5eec04b9-ed40-400a-a7f0-07cc748383f1\n",
      "[I 2024-11-11 16:00:14,115] Trial 0 finished with value: 0.9398828522185377 and parameters: {'n_estimators': 223, 'max_depth': 17, 'learning_rate': 0.19319594249839628, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.7994463919990924}. Best is trial 0 with value: 0.9398828522185377.\n",
      "[W 2024-11-11 16:00:31,578] Trial 1 failed with parameters: {'n_estimators': 468, 'max_depth': 24, 'learning_rate': 0.13839375880378535, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.797336813969866} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wojci\\AppData\\Local\\Temp\\ipykernel_38244\\2662077228.py\", line 61, in objective\n",
      "    model.fit(X_train_fold, y_train_fold)\n",
      "  File \"c:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 783, in fit\n",
      "    n_stages = self._fit_stages(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 879, in _fit_stages\n",
      "    raw_predictions = self._fit_stage(\n",
      "                      ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 496, in _fit_stage\n",
      "    _update_terminal_regions(\n",
      "  File \"c:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 256, in _update_terminal_regions\n",
      "    update = compute_update(y_, indices, neg_gradient, raw_prediction, k)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 212, in compute_update\n",
      "    neg_g = neg_gradient.take(indices, axis=0)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-11-11 16:00:31,581] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[216], line 74\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Set up Optuna study and optimize\u001b[39;00m\n\u001b[0;32m     73\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Retrieve the best parameters\u001b[39;00m\n\u001b[0;32m     77\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[216], line 61\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     58\u001b[0m X_val_fold \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_val_fold)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Fit the model on the training fold\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Predict on the validation fold\u001b[39;00m\n\u001b[0;32m     64\u001b[0m y_pred_fold \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val_fold)\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:783\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    782\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 783\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:879\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    872\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[0;32m    873\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[0;32m    874\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    875\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[0;32m    876\u001b[0m         )\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 879\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:496\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 496\u001b[0m \u001b[43m_update_terminal_regions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_for_tree_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# add tree to ensemble\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[i, k] \u001b[38;5;241m=\u001b[39m tree\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:256\u001b[0m, in \u001b[0;36m_update_terminal_regions\u001b[1;34m(loss, tree, X, y, neg_gradient, raw_prediction, sample_weight, sample_mask, learning_rate, k)\u001b[0m\n\u001b[0;32m    254\u001b[0m y_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mtake(indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    255\u001b[0m sw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight[indices]\n\u001b[1;32m--> 256\u001b[0m update \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_gradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# TODO: Multiply here by learning rate instead of everywhere else.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m tree\u001b[38;5;241m.\u001b[39mvalue[leaf, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m update\n",
      "File \u001b[1;32mc:\\Users\\wojci\\anaconda3\\envs\\Machine-Learning\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:212\u001b[0m, in \u001b[0;36m_update_terminal_regions.<locals>.compute_update\u001b[1;34m(y_, indices, neg_gradient, raw_prediction, k)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_update\u001b[39m(y_, indices, neg_gradient, raw_prediction, k):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# we take advantage that: y - prob = neg_gradient\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m     neg_g \u001b[38;5;241m=\u001b[39m \u001b[43mneg_gradient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m     prob \u001b[38;5;241m=\u001b[39m y_ \u001b[38;5;241m-\u001b[39m neg_g\n\u001b[0;32m    214\u001b[0m     K \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mn_classes\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on y_train and transform y_train\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest values for hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 30)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.3)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "        \n",
    "    # Initialize GradientBoostingClassifier with suggested hyperparameters\n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        subsample=subsample\n",
    "    )\n",
    "    \n",
    "    # Initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, val_index in skf.split(best_selected_features_df, y_train_encoded):\n",
    "        X_train_fold, X_val_fold = best_selected_features_df.iloc[train_index], best_selected_features_df.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_encoded[train_index], y_train_encoded[val_index]\n",
    "        \n",
    "        # Impute missing values using KNN impute\n",
    "        X_train_fold, X_val_fold = knn_impute(X_train_fold, X_val_fold, numerical_columns)\n",
    "\n",
    "        # Classify BMI based on age and BMI value\n",
    "        X_train_fold['bmi_class'] = X_train_fold.apply(classify_bmi_comprehensive, axis=1)\n",
    "        X_val_fold['bmi_class'] = X_val_fold.apply(classify_bmi_comprehensive, axis=1)\n",
    "\n",
    "        # Impute missing values using Iterative impute\n",
    "        X_train_fold, X_val_fold = iterative_impute(X_train_fold, X_val_fold)\n",
    "\n",
    "        # Initialize the scaler\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Fit the scaler on the training fold and transform both training and validation folds\n",
    "        X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Fit the model on the training fold\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predict on the validation fold\n",
    "        y_pred_fold = model.predict(X_val_fold)\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(y_val_fold, y_pred_fold, average='macro')\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# Set up Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Retrieve the best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d1e3a1",
   "metadata": {
    "id": "14d1e3a1"
   },
   "source": [
    "<a class=\"anchor\" id=\"\">\n",
    "\n",
    "# 4 & 5. Model & Assess (Modelling and Assessment)\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad01ff7",
   "metadata": {
    "id": "7ad01ff7"
   },
   "source": [
    "<img src=\"image/step4.png\" style=\"height:60px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89849818",
   "metadata": {
    "id": "89849818"
   },
   "source": [
    "### 4.1. Model Selection\n",
    "\n",
    "In this section you should take the time to train different predictive algorithms with the data that got to this stage and **use the approppriate model assessment metrics to decide which model you think is the best to address your problem**.\n",
    "\n",
    "**You are expected to present on your report the model performances of the different algorithms that you tested and discuss what informed your choice for a specific algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92285396",
   "metadata": {
    "id": "92285396"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f08f9c24",
   "metadata": {
    "id": "f08f9c24"
   },
   "source": [
    "### 4.2. Model Optimization\n",
    "\n",
    "After selecting the best algorithm (set of algorithms), you can try to optimize the performance of your model by fiddling with the algorithms' hyper-parameters and select the options that result on the best overall performance.\n",
    "\n",
    "Possible ways of doing this can be through:\n",
    "1. [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "2. [RandomSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "**While you are not required to show the results of all combinations of hyperparameters that you tried, you should at least discuss the what were the possible combinations used and which of them resulted in your best performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387961a5",
   "metadata": {
    "id": "387961a5",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebfaed02",
   "metadata": {
    "id": "ebfaed02"
   },
   "source": [
    "<a class=\"anchor\" id=\"\">\n",
    "\n",
    "# 5. Deploy\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24677b",
   "metadata": {
    "id": "dc24677b"
   },
   "source": [
    "<img src=\"image/step5.png\" style=\"height:60px\">\n",
    "\n",
    "### 5.0 Training a final model\n",
    "\n",
    "You used the previous steps of modelling and assessment to determine what would be best strategies when it comes to preprocessing, scaling, feature selection, algorithm and hyper-parameters you could find.\n",
    "\n",
    "**By this stage, all of those choices were already made**. For that reason, a split between training and validation is no longer necessary. **A good practice** would be to take the initial data and train a final model with all of the labeled data that you have available.\n",
    "\n",
    "**Everything is figured by this stage**, so, on a first level all you need to do is replicate the exact preprocessing, scaling and feature selection decisions you made before.<br>\n",
    "When it comes to the final model, all you have to do is creeate a new instance of your best algorithm with the best parameters that you uncovered (no need to try all algorithms and hyper-parameters again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ebbfc",
   "metadata": {
    "id": "191ebbfc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f38b4acc",
   "metadata": {
    "id": "f38b4acc"
   },
   "source": [
    "### 5.1. Import and Transform your test data\n",
    "\n",
    "Remember, the test data does not have the `outcome` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf433a",
   "metadata": {
    "id": "4dbf433a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30624f3a",
   "metadata": {
    "id": "30624f3a"
   },
   "source": [
    "### 5.2. Obtain Predictions on the test data from your final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abdf5b3",
   "metadata": {
    "id": "6abdf5b3",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27d4b2b2",
   "metadata": {
    "id": "27d4b2b2"
   },
   "source": [
    "### 5.3. Create a Dataframe containing the index of each row and its intended prediction and export it to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c3404",
   "metadata": {
    "id": "208c3404"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95e385c2",
   "metadata": {
    "id": "95e385c2"
   },
   "source": [
    "Submit the csv file to Kaggle to obtain the model performance of your model on the test data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Machine-Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
