{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad09b7f8",
   "metadata": {
    "id": "ad09b7f8"
   },
   "source": [
    "<b><font size=\"6\">Predictive Modelling Pipeline Template</font></b><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253d4d8",
   "metadata": {
    "id": "7253d4d8"
   },
   "source": [
    "In this notebook we present to you the main steps you should follow throughout your project.\n",
    "\n",
    "\n",
    "<b> Important: The numbered sections and subsections are merely indicative of some of the steps you should pay attention to in your project. <br>You are not required to strictly follow this order or to execute everything in separate cells.</b>\n",
    "    \n",
    "<img src=\"image/process_ML.png\" style=\"height:70px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b51dd532",
   "metadata": {
    "id": "b51dd532"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer  # Enable IterativeImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18852571",
   "metadata": {
    "id": "18852571"
   },
   "source": [
    "<a class=\"anchor\" id=\"\">\n",
    "\n",
    "# 1. Import data (Data Integration)\n",
    "\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaea6ca",
   "metadata": {
    "id": "2eaea6ca"
   },
   "source": [
    "<img src=\"image/step1.png\" style=\"height:60px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "nqPU0XFheKHi",
   "metadata": {
    "id": "nqPU0XFheKHi"
   },
   "outputs": [],
   "source": [
    "# Load the data in a simple way\n",
    "obesity_train_raw = pd.read_csv('../data/obesity_train.csv')\n",
    "obesity_test_raw = pd.read_csv('../data/obesity_test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54a29bcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729597252855,
     "user": {
      "displayName": "Michał Wójcik",
      "userId": "08591631202502653658"
     },
     "user_tz": -60
    },
    "id": "54a29bcb",
    "outputId": "eff7a2d5-4ce8-42c5-80cd-0781efa37051"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_freq</th>\n",
       "      <th>caloric_freq</th>\n",
       "      <th>devices_perday</th>\n",
       "      <th>eat_between_meals</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>marrital_status</th>\n",
       "      <th>meals_perday</th>\n",
       "      <th>...</th>\n",
       "      <th>parent_overweight</th>\n",
       "      <th>physical_activity_perweek</th>\n",
       "      <th>region</th>\n",
       "      <th>siblings</th>\n",
       "      <th>smoke</th>\n",
       "      <th>transportation</th>\n",
       "      <th>veggies_freq</th>\n",
       "      <th>water_daily</th>\n",
       "      <th>weight</th>\n",
       "      <th>obese_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Never</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Walk</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>5 or more</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>more than 2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Car</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>less than 1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age alcohol_freq caloric_freq devices_perday eat_between_meals  \\\n",
       "0   1  21.0        Never           no        up to 5         Sometimes   \n",
       "1   2  23.0   Frequently           no        up to 5         Sometimes   \n",
       "2   3   NaN   Frequently           no        up to 2         Sometimes   \n",
       "3   4  22.0    Sometimes           no        up to 2         Sometimes   \n",
       "4   5  22.0    Sometimes           no        up to 2         Sometimes   \n",
       "5   6  24.0   Frequently          yes        up to 5         Sometimes   \n",
       "6   7  21.0    Sometimes          yes        up to 5        Frequently   \n",
       "7   8  22.0    Sometimes           no        up to 2         Sometimes   \n",
       "8   9  41.0   Frequently          yes        up to 5         Sometimes   \n",
       "9  10  27.0    Sometimes          yes        up to 2         Sometimes   \n",
       "\n",
       "   gender  height  marrital_status  meals_perday  ... parent_overweight  \\\n",
       "0  Female    1.62              NaN           3.0  ...               yes   \n",
       "1    Male    1.80              NaN           3.0  ...               yes   \n",
       "2    Male    1.80              NaN           3.0  ...                no   \n",
       "3    Male    1.78              NaN           1.0  ...                no   \n",
       "4    Male    1.64              NaN           3.0  ...                no   \n",
       "5    Male    1.78              NaN           3.0  ...               yes   \n",
       "6  Female    1.72              NaN           3.0  ...               yes   \n",
       "7    Male    1.65              NaN           3.0  ...                no   \n",
       "8    Male    1.80              NaN           3.0  ...                no   \n",
       "9    Male    1.93              NaN           1.0  ...               yes   \n",
       "\n",
       "  physical_activity_perweek region siblings  smoke transportation  \\\n",
       "0                       NaN  LatAm      3.0     no         Public   \n",
       "1                    3 to 4  LatAm      0.0     no         Public   \n",
       "2                    3 to 4  LatAm      2.0     no           Walk   \n",
       "3                       NaN  LatAm      3.0     no         Public   \n",
       "4                 5 or more  LatAm      3.0     no         Public   \n",
       "5                    1 to 2  LatAm      2.0     no         Public   \n",
       "6                    3 to 4    NaN      2.0     no         Public   \n",
       "7                    3 to 4  LatAm      1.0     no         Public   \n",
       "8                    3 to 4  LatAm      0.0     no            Car   \n",
       "9                    1 to 2  LatAm      2.0     no         Public   \n",
       "\n",
       "  veggies_freq  water_daily weight          obese_level  \n",
       "0    Sometimes       1 to 2   64.0        Normal_Weight  \n",
       "1    Sometimes       1 to 2   77.0        Normal_Weight  \n",
       "2       Always       1 to 2   87.0   Overweight_Level_I  \n",
       "3    Sometimes       1 to 2   90.0  Overweight_Level_II  \n",
       "4    Sometimes       1 to 2   53.0        Normal_Weight  \n",
       "5       Always       1 to 2   64.0        Normal_Weight  \n",
       "6    Sometimes       1 to 2   80.0  Overweight_Level_II  \n",
       "7       Always  more than 2   56.0        Normal_Weight  \n",
       "8    Sometimes       1 to 2   99.0       Obesity_Type_I  \n",
       "9    Sometimes  less than 1  102.0  Overweight_Level_II  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_train_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffee8f19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1729597253173,
     "user": {
      "displayName": "Michał Wójcik",
      "userId": "08591631202502653658"
     },
     "user_tz": -60
    },
    "id": "ffee8f19",
    "outputId": "22ed1cf5-de0d-4ad1-c554-7f49672fcb9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_freq</th>\n",
       "      <th>caloric_freq</th>\n",
       "      <th>devices_perday</th>\n",
       "      <th>eat_between_meals</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>marrital_status</th>\n",
       "      <th>meals_perday</th>\n",
       "      <th>monitor_calories</th>\n",
       "      <th>parent_overweight</th>\n",
       "      <th>physical_activity_perweek</th>\n",
       "      <th>region</th>\n",
       "      <th>siblings</th>\n",
       "      <th>smoke</th>\n",
       "      <th>transportation</th>\n",
       "      <th>veggies_freq</th>\n",
       "      <th>water_daily</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1612</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>5 or more</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>more than 2</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1613</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Car</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1614</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1615</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Never</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1616</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>more than 2</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1617</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>less than 1</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1618</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Always</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1619</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Never</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Car</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1620</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Never</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Car</td>\n",
       "      <td>Always</td>\n",
       "      <td>less than 1</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1621</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>LatAm</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Car</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   age alcohol_freq caloric_freq devices_perday eat_between_meals  \\\n",
       "0  1612  21.0    Sometimes           no        up to 2         Sometimes   \n",
       "1  1613  29.0    Sometimes          yes        up to 2         Sometimes   \n",
       "2  1614  23.0    Sometimes          NaN        up to 2         Sometimes   \n",
       "3  1615  22.0        Never          yes        up to 5         Sometimes   \n",
       "4  1616  26.0    Sometimes          yes    more than 5        Frequently   \n",
       "5  1617  23.0    Sometimes          yes        up to 5         Sometimes   \n",
       "6  1618  22.0    Sometimes           no        up to 5            Always   \n",
       "7  1619  29.0        Never          yes        up to 2         Sometimes   \n",
       "8  1620  30.0        Never          yes        up to 2        Frequently   \n",
       "9  1621  23.0    Sometimes          yes        up to 5        Frequently   \n",
       "\n",
       "   gender  height  marrital_status  meals_perday monitor_calories  \\\n",
       "0  Female    1.52              NaN           3.0              yes   \n",
       "1    Male    1.62              NaN           3.0               no   \n",
       "2  Female    1.50              NaN           3.0               no   \n",
       "3    Male    1.72              NaN           3.0               no   \n",
       "4    Male    1.85              NaN           3.0               no   \n",
       "5    Male    1.77              NaN           1.0               no   \n",
       "6  Female    1.70              NaN           3.0              yes   \n",
       "7  Female    1.53              NaN           1.0               no   \n",
       "8  Female    1.71              NaN           4.0               no   \n",
       "9  Female    1.60              NaN           4.0               no   \n",
       "\n",
       "  parent_overweight physical_activity_perweek region  siblings smoke  \\\n",
       "0               yes                 5 or more  LatAm       3.0   yes   \n",
       "1                no                       NaN  LatAm       3.0    no   \n",
       "2               yes                    1 to 2  LatAm       2.0    no   \n",
       "3               yes                    1 to 2  LatAm       1.0    no   \n",
       "4               yes                    3 to 4  LatAm       1.0    no   \n",
       "5               yes                    1 to 2  LatAm       2.0    no   \n",
       "6               yes                    3 to 4  LatAm       1.0    no   \n",
       "7                no                       NaN  LatAm       0.0    no   \n",
       "8               yes                       NaN  LatAm       0.0   yes   \n",
       "9                no                    3 to 4  LatAm       3.0    no   \n",
       "\n",
       "  transportation veggies_freq  water_daily  weight  \n",
       "0         Public       Always  more than 2    56.0  \n",
       "1            Car    Sometimes       1 to 2    53.0  \n",
       "2      Motorbike       Always       1 to 2     NaN  \n",
       "3         Public    Sometimes       1 to 2    68.0  \n",
       "4         Public       Always  more than 2   105.0  \n",
       "5         Public       Always  less than 1    60.0  \n",
       "6         Public       Always       1 to 2     NaN  \n",
       "7            Car    Sometimes       1 to 2    78.0  \n",
       "8            Car       Always  less than 1    82.0  \n",
       "9            Car    Sometimes       1 to 2    52.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_test_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d2690",
   "metadata": {
    "id": "2f5d2690"
   },
   "source": [
    "<a class=\"anchor\" id=\"\">\n",
    "\n",
    "# 2. Explore data (Data access, exploration and understanding)\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dcd9d4",
   "metadata": {
    "id": "a4dcd9d4"
   },
   "source": [
    "<img src=\"image/step2.png\" style=\"height:60px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae9956",
   "metadata": {
    "id": "d7ae9956"
   },
   "source": [
    "Remember, this step is very important as it is at this stage that you will really look into the data that you have. Generally speaking, if you do well at this stage, the following stages will be very smooth.\n",
    "\n",
    "Moreover, you should also take the time to find meaningful patterns on the data: what interesting relationships can be found between the variables and how can that knowledge be inform your future decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acae7518",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1729597253173,
     "user": {
      "displayName": "Michał Wójcik",
      "userId": "08591631202502653658"
     },
     "user_tz": -60
    },
    "id": "acae7518",
    "outputId": "457f0ab6-1fed-4b5a-fede-ba27e9337c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1611 entries, 0 to 1610\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         1611 non-null   int64  \n",
      " 1   age                        1545 non-null   float64\n",
      " 2   alcohol_freq               1575 non-null   object \n",
      " 3   caloric_freq               1591 non-null   object \n",
      " 4   devices_perday             1589 non-null   object \n",
      " 5   eat_between_meals          1552 non-null   object \n",
      " 6   gender                     1591 non-null   object \n",
      " 7   height                     1597 non-null   float64\n",
      " 8   marrital_status            0 non-null      float64\n",
      " 9   meals_perday               1602 non-null   float64\n",
      " 10  monitor_calories           1572 non-null   object \n",
      " 11  parent_overweight          1591 non-null   object \n",
      " 12  physical_activity_perweek  1046 non-null   object \n",
      " 13  region                     1544 non-null   object \n",
      " 14  siblings                   1599 non-null   float64\n",
      " 15  smoke                      1599 non-null   object \n",
      " 16  transportation             1571 non-null   object \n",
      " 17  veggies_freq               1585 non-null   object \n",
      " 18  water_daily                1577 non-null   object \n",
      " 19  weight                     1558 non-null   float64\n",
      " 20  obese_level                1611 non-null   object \n",
      "dtypes: float64(6), int64(1), object(14)\n",
      "memory usage: 264.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display information about the training dataset\n",
    "obesity_train_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186631e",
   "metadata": {
    "id": "1186631e"
   },
   "source": [
    "<a class=\"anchor\" id=\"\">\n",
    "\n",
    "# 3. Modify data (Data preparation)\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01adeef2",
   "metadata": {
    "id": "01adeef2"
   },
   "source": [
    "<img src=\"image/step3.png\" style=\"height:60px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12772f7",
   "metadata": {
    "id": "d12772f7"
   },
   "source": [
    "Use this section to apply transformations to your dataset.\n",
    "\n",
    "Remember that your decisions at this step should be exclusively informed by your **training data**. While you will need to split your data between training and validation, how that split will be made and how to apply the approppriate transformations will depend on the type of model assessment solution you select for your project (each has its own set of advantages and disadvantages that you need to consider). **Please find a list of possible methods for model assessment below**:\n",
    "\n",
    "1. **Holdout method**\n",
    "2. **Repeated Holdout method**\n",
    "3. **Cross-Validation**\n",
    "\n",
    "__Note:__ Instead of creating different sections for the treatment of training and validation data, you can make the transformations in the same cell. There is no need to create a specific section for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6b621",
   "metadata": {
    "id": "eff6b621"
   },
   "source": [
    "### 3.1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "238c088d",
   "metadata": {
    "id": "238c088d"
   },
   "outputs": [],
   "source": [
    "# Drop the 'marrital_status' and 'region' columns from the dataset\n",
    "obesity_train = obesity_train_raw.drop(columns=['marrital_status', 'region'])\n",
    "obesity_test = obesity_test_raw.drop(columns=['marrital_status', 'region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "Xfez5_d4e70T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1729608382028,
     "user": {
      "displayName": "Skeletal",
      "userId": "03029484600494071692"
     },
     "user_tz": -60
    },
    "id": "Xfez5_d4e70T",
    "outputId": "291b2dda-d1c9-4e6d-f082-92997666448a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_freq</th>\n",
       "      <th>caloric_freq</th>\n",
       "      <th>devices_perday</th>\n",
       "      <th>eat_between_meals</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>meals_perday</th>\n",
       "      <th>monitor_calories</th>\n",
       "      <th>parent_overweight</th>\n",
       "      <th>physical_activity_perweek</th>\n",
       "      <th>siblings</th>\n",
       "      <th>smoke</th>\n",
       "      <th>transportation</th>\n",
       "      <th>veggies_freq</th>\n",
       "      <th>water_daily</th>\n",
       "      <th>weight</th>\n",
       "      <th>obese_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Never</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Walk</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>up to 2</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.64</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>5 or more</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>131.0</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>134.0</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>134.0</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>more than 2</td>\n",
       "      <td>133.0</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>up to 5</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public</td>\n",
       "      <td>Always</td>\n",
       "      <td>more than 2</td>\n",
       "      <td>133.0</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1611 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age alcohol_freq caloric_freq devices_perday eat_between_meals  gender  \\\n",
       "id                                                                              \n",
       "1     21.0        Never           no        up to 5         Sometimes  Female   \n",
       "2     23.0   Frequently           no        up to 5         Sometimes    Male   \n",
       "3      NaN   Frequently           no        up to 2         Sometimes    Male   \n",
       "4     22.0    Sometimes           no        up to 2         Sometimes    Male   \n",
       "5     22.0    Sometimes           no        up to 2         Sometimes    Male   \n",
       "...    ...          ...          ...            ...               ...     ...   \n",
       "1607  21.0    Sometimes          NaN        up to 5         Sometimes  Female   \n",
       "1608  22.0    Sometimes          yes        up to 5         Sometimes  Female   \n",
       "1609  23.0    Sometimes          yes        up to 5         Sometimes  Female   \n",
       "1610  24.0    Sometimes          yes        up to 5         Sometimes  Female   \n",
       "1611  24.0    Sometimes          yes        up to 5         Sometimes  Female   \n",
       "\n",
       "      height  meals_perday monitor_calories parent_overweight  \\\n",
       "id                                                              \n",
       "1       1.62           3.0               no               yes   \n",
       "2       1.80           3.0               no               yes   \n",
       "3       1.80           3.0               no                no   \n",
       "4       1.78           1.0               no                no   \n",
       "5       1.64           3.0               no                no   \n",
       "...      ...           ...              ...               ...   \n",
       "1607    1.73           3.0               no               yes   \n",
       "1608    1.75           3.0               no               yes   \n",
       "1609    1.75           3.0               no               yes   \n",
       "1610    1.74           3.0               no               yes   \n",
       "1611    1.74           3.0               no               yes   \n",
       "\n",
       "     physical_activity_perweek  siblings smoke transportation veggies_freq  \\\n",
       "id                                                                           \n",
       "1                          NaN       3.0    no         Public    Sometimes   \n",
       "2                       3 to 4       0.0    no         Public    Sometimes   \n",
       "3                       3 to 4       2.0    no           Walk       Always   \n",
       "4                          NaN       3.0    no         Public    Sometimes   \n",
       "5                    5 or more       3.0    no         Public    Sometimes   \n",
       "...                        ...       ...   ...            ...          ...   \n",
       "1607                    3 to 4       1.0    no         Public       Always   \n",
       "1608                    1 to 2       0.0    no            NaN       Always   \n",
       "1609                    1 to 2       0.0    no         Public       Always   \n",
       "1610                    1 to 2       0.0    no         Public       Always   \n",
       "1611                    1 to 2       0.0    no         Public       Always   \n",
       "\n",
       "      water_daily  weight          obese_level  \n",
       "id                                              \n",
       "1          1 to 2    64.0        Normal_Weight  \n",
       "2          1 to 2    77.0        Normal_Weight  \n",
       "3          1 to 2    87.0   Overweight_Level_I  \n",
       "4          1 to 2    90.0  Overweight_Level_II  \n",
       "5          1 to 2    53.0        Normal_Weight  \n",
       "...           ...     ...                  ...  \n",
       "1607       1 to 2   131.0     Obesity_Type_III  \n",
       "1608       1 to 2   134.0     Obesity_Type_III  \n",
       "1609       1 to 2   134.0     Obesity_Type_III  \n",
       "1610  more than 2   133.0     Obesity_Type_III  \n",
       "1611  more than 2   133.0     Obesity_Type_III  \n",
       "\n",
       "[1611 rows x 18 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_train.set_index('id', inplace=True)\n",
    "obesity_test.set_index('id', inplace=True)\n",
    "obesity_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7rfkILCKkbzS",
   "metadata": {
    "id": "7rfkILCKkbzS"
   },
   "outputs": [],
   "source": [
    "# Selecting outliers for which the age is out of scope. Or the weight classification is suspiciously low for the value given\n",
    "outliers = obesity_train[\n",
    "    ((obesity_train['age'] < 16) & ~(obesity_train['age'].isna())) |\n",
    "    ((obesity_train['age'] > 56) & ~(obesity_train['age'].isna())) |\n",
    "    ((obesity_train['weight'] > 167) & ~(obesity_train['weight'].isna()))\n",
    "]\n",
    "obesity_train.drop(outliers.index, inplace=True)\n",
    "obesity_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "gz9nal_KPUGu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1729608389845,
     "user": {
      "displayName": "Skeletal",
      "userId": "03029484600494071692"
     },
     "user_tz": -60
    },
    "id": "gz9nal_KPUGu",
    "outputId": "e4946bf0-1b24-4a80-9c85-68be30f0295c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1605, 18)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_train.shape # Shape adds up to our expectation (6 rows deleted) 1611 -> 1605 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813e2d3",
   "metadata": {},
   "source": [
    "# Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f636105",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = obesity_train.select_dtypes(include='object').columns\n",
    "numerical_columns = obesity_train.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab7f7048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'alcohol_freq', 'caloric_freq', 'devices_perday',\n",
       "       'eat_between_meals', 'gender', 'height', 'meals_perday',\n",
       "       'monitor_calories', 'parent_overweight', 'physical_activity_perweek',\n",
       "       'siblings', 'smoke', 'transportation', 'veggies_freq', 'water_daily',\n",
       "       'weight', 'obese_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d80d9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashmap = {\n",
    "\"Never\": 0,\n",
    "\"Sometimes\": 1,\n",
    "\"Frequently\": 2,\n",
    "\"Always\": 3,\n",
    "\n",
    "\"No Activity\": 0,\n",
    "\"up to 2\": 1,\n",
    "\"up to 5\": 2,\n",
    "\"more than 5\": 3,\n",
    "\n",
    "\"less than 1\": 1,\n",
    "\"1 to 2\": 2,\n",
    "\"more than 2\": 3,\n",
    "\"3 to 4\": 4,\n",
    "\"5 or more\": 5,\n",
    "\n",
    "\"Bicycle\": 1,\n",
    "\"Car\": 3,\n",
    "\"Motorbike\": 3,\n",
    "\"Public\": 2,\n",
    "\"Walk\": 0,\n",
    "\n",
    "\"no\": 0,\n",
    "\"yes\": 1,\n",
    "\n",
    "\"Male\": 0,\n",
    "\"Female\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c59ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually encode data\n",
    "\n",
    "columns = ['alcohol_freq',\n",
    " 'caloric_freq',\n",
    " 'devices_perday',\n",
    " 'eat_between_meals',\n",
    " 'gender',\n",
    " 'monitor_calories',\n",
    " 'parent_overweight',\n",
    " 'physical_activity_perweek',\n",
    " 'smoke',\n",
    " 'transportation',\n",
    " 'veggies_freq',\n",
    " 'water_daily',\n",
    " 'meals_perday',\n",
    " \"siblings\"]\n",
    "\n",
    "for target in columns:\n",
    "    obesity_train[target] = obesity_train[target].replace(hashmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90872b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                           65\n",
       "alcohol_freq                  36\n",
       "caloric_freq                  20\n",
       "devices_perday                21\n",
       "eat_between_meals             59\n",
       "gender                        20\n",
       "height                        13\n",
       "meals_perday                   9\n",
       "monitor_calories              39\n",
       "parent_overweight             20\n",
       "physical_activity_perweek    564\n",
       "siblings                      12\n",
       "smoke                         12\n",
       "transportation                40\n",
       "veggies_freq                  26\n",
       "water_daily                   34\n",
       "weight                        53\n",
       "obese_level                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_train_encoded = obesity_train.copy()\n",
    "obesity_train_encoded.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0QWZatS0_nup",
   "metadata": {
    "id": "0QWZatS0_nup"
   },
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93887093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with mode and median as the first null-handling resolution. Will be re-approached with further iterations on the model itself\n",
    "\n",
    "obesity_train_encoded['physical_activity_perweek'].fillna(0, inplace=True) # ASSUMPTION: There is no 0 value in the scope. We assume nulls are the people who dont work out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7188d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = obesity_train_encoded.drop(columns='obese_level')\n",
    "y = obesity_train_encoded[['obese_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "Bs2-yQrj-2MO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1729597253173,
     "user": {
      "displayName": "Michał Wójcik",
      "userId": "08591631202502653658"
     },
     "user_tz": -60
    },
    "id": "Bs2-yQrj-2MO",
    "outputId": "175cf935-ac35-4b93-dc15-4991acc43e03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          65\n",
       "alcohol_freq                 36\n",
       "caloric_freq                 20\n",
       "devices_perday               21\n",
       "eat_between_meals            59\n",
       "gender                       20\n",
       "height                       13\n",
       "meals_perday                  9\n",
       "monitor_calories             39\n",
       "parent_overweight            20\n",
       "physical_activity_perweek     0\n",
       "siblings                     12\n",
       "smoke                        12\n",
       "transportation               40\n",
       "veggies_freq                 26\n",
       "water_daily                  34\n",
       "weight                       53\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2516007f",
   "metadata": {},
   "source": [
    "# Original imputing function\n",
    "\n",
    "\n",
    "\n",
    "data_knnimputer_train = X.copy()\n",
    "\n",
    "numerical_columns_features = numerical_columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_knnimputer_train[numerical_columns_features] = scaler.fit_transform(data_knnimputer_train[numerical_columns_features])\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "data_knnimputer_train[numerical_columns_features] = knn_imputer.fit_transform(data_knnimputer_train[numerical_columns_features])\n",
    "\n",
    "data_knnimputer_train[numerical_columns_features] = scaler.inverse_transform(data_knnimputer_train[numerical_columns_features])\n",
    "\n",
    "print(data_knnimputer_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ed988027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_impute(X_train, X_val, numerical_columns, n_neighbors=5):\n",
    "\n",
    "    # Create copies for KNN imputation\n",
    "    data_knnimputer_train = X_train.copy()\n",
    "    data_knnimputer_val = X_val.copy()\n",
    "\n",
    "    # Specify the columns to scale\n",
    "    numerical_columns_features = numerical_columns\n",
    "\n",
    "    # Scale the data for KNN imputation\n",
    "    scaler = StandardScaler()\n",
    "    data_knnimputer_train[numerical_columns_features] = scaler.fit_transform(data_knnimputer_train[numerical_columns_features])\n",
    "    data_knnimputer_val[numerical_columns_features] = scaler.transform(data_knnimputer_val[numerical_columns_features])\n",
    "\n",
    "    # Perform KNN imputation\n",
    "    knn_imputer = KNNImputer(n_neighbors=n_neighbors, weights='uniform')\n",
    "    data_knnimputer_train[numerical_columns_features] = knn_imputer.fit_transform(data_knnimputer_train[numerical_columns_features])\n",
    "    data_knnimputer_val[numerical_columns_features] = knn_imputer.transform(data_knnimputer_val[numerical_columns_features])\n",
    "\n",
    "    # Inverse transform to original scale\n",
    "    data_knnimputer_train[numerical_columns_features] = scaler.inverse_transform(data_knnimputer_train[numerical_columns_features])\n",
    "    data_knnimputer_val[numerical_columns_features] = scaler.inverse_transform(data_knnimputer_val[numerical_columns_features])\n",
    "\n",
    "    return data_knnimputer_train, data_knnimputer_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6a925",
   "metadata": {},
   "source": [
    "Add BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "KwdC5nPyxzt4",
   "metadata": {
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1729609910202,
     "user": {
      "displayName": "Michał Wójcik",
      "userId": "08591631202502653658"
     },
     "user_tz": -60
    },
    "id": "KwdC5nPyxzt4"
   },
   "outputs": [],
   "source": [
    "def classify_bmi_comprehensive(row):\n",
    "    \"\"\"\n",
    "    Classify BMI based on age and BMI value.\n",
    "\n",
    "    Input:\n",
    "    row: A Pandas row with 'weight', 'height', and 'age' columns.\n",
    "\n",
    "    Output:\n",
    "    Returns a string that classifies the individual into BMI categories.\n",
    "    \"\"\"\n",
    "    # Check if weight and height are valid\n",
    "    if row['height'] <= 0 or row['weight'] <= 0:\n",
    "        return 'Invalid data'\n",
    "\n",
    "    # Calculate BMI\n",
    "    bmi = row['weight'] / (row['height'] ** 2)\n",
    "\n",
    "    # Age group: Children (2-19 years)\n",
    "    if 2 <= row['age'] < 20:\n",
    "        if bmi < 14:\n",
    "            return 0 # Underweight\n",
    "        elif 14 <= bmi < 18:\n",
    "            return 1 # Normal weight\n",
    "        elif 18 <= bmi < 21:\n",
    "            return 2 # Overweight\n",
    "        else:\n",
    "            return 3 # Obesity 1\n",
    "\n",
    "    # Age group: Adults (20-64 years)\n",
    "    elif 20 <= row['age'] < 65:\n",
    "        if bmi < 18.5:\n",
    "            return 0 # \"Underweight\"\n",
    "        elif 18.5 <= bmi < 25:\n",
    "            return 1 # \"Healthy Weight\"\n",
    "        elif 25 <= bmi < 30:\n",
    "            return 2 #\"Overweight\"\n",
    "        elif 30<= bmi < 35:\n",
    "            return 3 #\"Obese Class 1\"\n",
    "        elif 35 <= bmi < 40:\n",
    "            return 4 #\"Obese Class 2\"\n",
    "        else:\n",
    "            return 5 #\"Obese Class 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a423e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_bmi(df):\n",
    "    \"\"\"\n",
    "    Classify BMI based on age and BMI value for an entire DataFrame.\n",
    "\n",
    "    Input:\n",
    "    df: A Pandas DataFrame with 'weight', 'height', and 'age' columns.\n",
    "\n",
    "    Output:\n",
    "    Returns a series with BMI classifications.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate BMI for all rows\n",
    "    bmi = df['weight'] / (df['height'] ** 2)\n",
    "    \n",
    "    # Initialize results array\n",
    "    classifications = pd.Series(index=df.index, dtype=int)\n",
    "    \n",
    "    # Invalid data mask\n",
    "    invalid_mask = (df['height'] <= 0) | (df['weight'] <= 0)\n",
    "    \n",
    "    # Children mask (2-19 years)\n",
    "    children_mask = (df['age'] >= 2) & (df['age'] < 20)\n",
    "    \n",
    "    # Adult mask (20-64 years)\n",
    "    adult_mask = (df['age'] >= 20) & (df['age'] < 65)\n",
    "    \n",
    "    # Classify children\n",
    "    children_class = pd.Series(index=df.index, dtype=int)\n",
    "    children_class[bmi < 14] = 0\n",
    "    children_class[(bmi >= 14) & (bmi < 18)] = 1\n",
    "    children_class[(bmi >= 18) & (bmi < 21)] = 2\n",
    "    children_class[bmi >= 21] = 3\n",
    "    \n",
    "    # Classify adults\n",
    "    adult_class = pd.Series(index=df.index, dtype=int)\n",
    "    adult_class[bmi < 18.5] = 0\n",
    "    adult_class[(bmi >= 18.5) & (bmi < 25)] = 1\n",
    "    adult_class[(bmi >= 25) & (bmi < 30)] = 2\n",
    "    adult_class[(bmi >= 30) & (bmi < 35)] = 3\n",
    "    adult_class[(bmi >= 35) & (bmi < 40)] = 4\n",
    "    adult_class[bmi >= 40] = 5\n",
    "    \n",
    "    # Combine classifications\n",
    "    classifications[children_mask] = children_class[children_mask]\n",
    "    classifications[adult_mask] = adult_class[adult_mask]\n",
    "    classifications[invalid_mask] = -1  # Invalid data\n",
    "    \n",
    "    return classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e026ec",
   "metadata": {},
   "source": [
    "# Manually encode the obesity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "681afb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_obesity = {\n",
    " 'Normal_Weight': 1,\n",
    " 'Overweight_Level_I': 2,\n",
    " 'Overweight_Level_II': 3,\n",
    " 'Obesity_Type_I': 4,\n",
    " 'Insufficient_Weight': 5,\n",
    " 'Obesity_Type_II': 6,\n",
    " 'Obesity_Type_III': 7\n",
    " }\n",
    "\n",
    "y = y['obese_level'].replace(hash_obesity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67a6917",
   "metadata": {},
   "source": [
    "Impute categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8ea9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IterativeImputer with KNeighborsClassifier for categorical data imputation\n",
    "#iterative_imputer = IterativeImputer(estimator=KNeighborsClassifier(n_neighbors=5), max_iter=10, random_state=42, \n",
    "#                                     skip_complete=True)\n",
    "\n",
    "# Perform imputation on the encoded categorical data\n",
    "#data_knnimputer_train_imputed = iterative_imputer.fit_transform(data_knnimputer_train)\n",
    "\n",
    "# Convert back to DataFrame and assign original column names\n",
    "#data_knnimputer_train = pd.DataFrame(data_knnimputer_train_imputed, columns=data_knnimputer_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef152e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IterativeImputer with KNeighborsClassifier for categorical data imputation\n",
    "#iterative_imputer = IterativeImputer(estimator=KNeighborsClassifier(n_neighbors=5), max_iter=10, random_state=42, \n",
    "#                                     skip_complete=True)\n",
    "\n",
    "# Perform imputation on the encoded categorical data\n",
    "#data_knnimputer_train_imputed = iterative_imputer.fit_transform(data_knnimputer_train)\n",
    "\n",
    "# Convert back to DataFrame and assign original column names\n",
    "#data_knnimputer_train = pd.DataFrame(data_knnimputer_train_imputed, columns=data_knnimputer_train.columns)\n",
    "\n",
    "\n",
    "def iterative_impute(X_train, X_val, estimator=KNeighborsClassifier(n_neighbors=5), max_iter=10, random_state=42):\n",
    "    # Initialize IterativeImputer with the given estimator for categorical data imputation\n",
    "    iterative_imputer = IterativeImputer(estimator=estimator, max_iter=max_iter, random_state=random_state, skip_complete=True)\n",
    "    \n",
    "    # Perform imputation on the training and validation data\n",
    "    X_train_imputed = iterative_imputer.fit_transform(X_train)\n",
    "    X_val_imputed = iterative_imputer.transform(X_val)\n",
    "    \n",
    "    # Convert back to DataFrame and assign original column names\n",
    "    X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train.columns)\n",
    "    X_val_imputed = pd.DataFrame(X_val_imputed, columns=X_val.columns)\n",
    "    \n",
    "    return X_train_imputed, X_val_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0036efe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          65\n",
       "alcohol_freq                 36\n",
       "caloric_freq                 20\n",
       "devices_perday               21\n",
       "eat_between_meals            59\n",
       "gender                       20\n",
       "height                       13\n",
       "meals_perday                  9\n",
       "monitor_calories             39\n",
       "parent_overweight            20\n",
       "physical_activity_perweek     0\n",
       "siblings                     12\n",
       "smoke                        12\n",
       "transportation               40\n",
       "veggies_freq                 26\n",
       "water_daily                  34\n",
       "weight                       53\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eea0f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_life_score(df):\n",
    "    life_columns = [\n",
    "        'alcohol_freq',\n",
    "        'caloric_freq',\n",
    "        'devices_perday',\n",
    "        'eat_between_meals',\n",
    "        'monitor_calories',\n",
    "        'physical_activity_perweek',\n",
    "        'smoke',\n",
    "        'transportation',\n",
    "        'veggies_freq',\n",
    "        'water_daily',\n",
    "    ]\n",
    "\n",
    "    df[\"life\"] = 0\n",
    "    for column in life_columns:\n",
    "        if column in df.columns:\n",
    "            df[\"life\"] += df[column]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4de74",
   "metadata": {
    "id": "97a4de74"
   },
   "source": [
    "### 3.3. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478971ad",
   "metadata": {},
   "source": [
    "# Value scaling - finally done at the level of each fold so no prior scaling needed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale_age = StandardScaler().fit(encoded_train[[\"age\"]])\n",
    "scale_height = StandardScaler().fit(encoded_train[[\"height\"]])\n",
    "scale_weight = StandardScaler().fit(encoded_train[[\"weight\"]]) # Statistical analysis justifies the need to use RobustScaler on this one\n",
    "\n",
    "dfs = [encoded_train] # Transform both dataframes\n",
    "for df in dfs:\n",
    "    new_age = scale_age.transform(df[[\"age\"]])\n",
    "    new_height = scale_height.transform(df[[\"height\"]])\n",
    "    new_weight = scale_weight.transform(df[[\"weight\"]])\n",
    "\n",
    "    # Replace columns\n",
    "    df[\"age\"] = new_age\n",
    "    df[\"height\"] = new_height\n",
    "    df[\"weight\"] = new_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_scale = encoded_train.columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "encoded_train[columns_to_scale] = scaler.fit_transform(encoded_train[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee111e6e",
   "metadata": {
    "id": "ee111e6e"
   },
   "source": [
    "### 3.4. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "66c237cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.copy()\n",
    "y_train = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7f882da4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m X_val_fold[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbmi_class\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m X_val_fold\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: classify_bmi_comprehensive(row), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Impute missing values using Iterative impute\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m X_train_fold, X_val_fold \u001b[38;5;241m=\u001b[39m iterative_impute(X_train_fold, X_val_fold)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Add life feature\u001b[39;00m\n\u001b[0;32m     25\u001b[0m add_life_score(X_train_fold)\n",
      "Cell \u001b[1;32mIn[53], line 17\u001b[0m, in \u001b[0;36miterative_impute\u001b[1;34m(X_train, X_val, estimator, max_iter, random_state)\u001b[0m\n\u001b[0;32m     14\u001b[0m iterative_imputer \u001b[38;5;241m=\u001b[39m IterativeImputer(estimator\u001b[38;5;241m=\u001b[39mestimator, max_iter\u001b[38;5;241m=\u001b[39mmax_iter, random_state\u001b[38;5;241m=\u001b[39mrandom_state, skip_complete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Perform imputation on the training and validation data\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m X_train_imputed \u001b[38;5;241m=\u001b[39m iterative_imputer\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m     18\u001b[0m X_val_imputed \u001b[38;5;241m=\u001b[39m iterative_imputer\u001b[38;5;241m.\u001b[39mtransform(X_val)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Convert back to DataFrame and assign original column names\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:789\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat_idx \u001b[38;5;129;01min\u001b[39;00m ordered_idx:\n\u001b[0;32m    786\u001b[0m     neighbor_feat_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_neighbor_feat_idx(\n\u001b[0;32m    787\u001b[0m         n_features, feat_idx, abs_corr_mat\n\u001b[0;32m    788\u001b[0m     )\n\u001b[1;32m--> 789\u001b[0m     Xt, estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impute_one_feature(\n\u001b[0;32m    790\u001b[0m         Xt,\n\u001b[0;32m    791\u001b[0m         mask_missing_values,\n\u001b[0;32m    792\u001b[0m         feat_idx,\n\u001b[0;32m    793\u001b[0m         neighbor_feat_idx,\n\u001b[0;32m    794\u001b[0m         estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    795\u001b[0m         fit_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    796\u001b[0m         params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[0;32m    797\u001b[0m     )\n\u001b[0;32m    798\u001b[0m     estimator_triplet \u001b[38;5;241m=\u001b[39m _ImputerTriplet(\n\u001b[0;32m    799\u001b[0m         feat_idx, neighbor_feat_idx, estimator\n\u001b[0;32m    800\u001b[0m     )\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimputation_sequence_\u001b[38;5;241m.\u001b[39mappend(estimator_triplet)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:408\u001b[0m, in \u001b[0;36mIterativeImputer._impute_one_feature\u001b[1;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode, params)\u001b[0m\n\u001b[0;32m    406\u001b[0m missing_row_mask \u001b[38;5;241m=\u001b[39m mask_missing_values[:, feat_idx]\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit_mode:\n\u001b[1;32m--> 408\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[0;32m    409\u001b[0m         _safe_indexing(X_filled, neighbor_feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[0;32m    411\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    412\u001b[0m     )\n\u001b[0;32m    413\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[0;32m    414\u001b[0m         _safe_indexing(X_filled, feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[0;32m    416\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    417\u001b[0m     )\n\u001b[0;32m    418\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:176\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_indexing\u001b[39m(X, indices, \u001b[38;5;241m*\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return rows, items or columns of X using indices.\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    .. warning::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    array([1, 3, 5])\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the Decision Tree model\n",
    "tree = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Stratified K-Fold Cross Validation\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Impute missing values using KNN impute\n",
    "    X_train_fold, X_val_fold = knn_impute(X_train_fold, X_val_fold, numerical_columns)\n",
    "\n",
    "    # Classify BMI based on age and BMI value\n",
    "    X_train_fold['bmi_class'] = X_train_fold.apply(lambda row: classify_bmi_comprehensive(row), axis=1)\n",
    "    X_val_fold['bmi_class'] = X_val_fold.apply(lambda row: classify_bmi_comprehensive(row), axis=1)\n",
    "\n",
    "    # Impute missing values using Iterative impute\n",
    "    X_train_fold, X_val_fold = iterative_impute(X_train_fold, X_val_fold)\n",
    "\n",
    "    # Add life feature\n",
    "    add_life_score(X_train_fold)\n",
    "    add_life_score(X_val_fold)\n",
    "    \n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler on the training fold and transform both training and validation folds\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "    \n",
    "    # Fit the model on the training fold\n",
    "    tree.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_pred_fold = tree.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_val_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print the average F1 score\n",
    "print(f\"Average F1 Score: {np.mean(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68704670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.9440912121684606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "tree_gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Stratified K-Fold Cross Validation\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Impute missing values using KNN impute\n",
    "    X_train_fold, X_val_fold = knn_impute(X_train_fold, X_val_fold, numerical_columns)\n",
    "\n",
    "    # Classify BMI based on age and BMI value\n",
    "    X_train_fold['bmi_class'] = X_train_fold.apply(lambda row: classify_bmi_comprehensive(row), axis=1)\n",
    "    X_val_fold['bmi_class'] = X_val_fold.apply(lambda row: classify_bmi_comprehensive(row), axis=1)\n",
    "\n",
    "    # Impute missing values using Iterative impute\n",
    "    X_train_fold, X_val_fold = iterative_impute(X_train_fold, X_val_fold)\n",
    "\n",
    "    # Add life feature\n",
    "    add_life_score(X_train_fold)\n",
    "    add_life_score(X_val_fold)\n",
    "    \n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler on the training fold and transform both training and validation folds\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "\n",
    "    # Fit the model on the training fold\n",
    "    tree_gb.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_pred_fold = tree_gb.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_val_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print the average F1 score\n",
    "print(f\"Average F1 Score: {np.mean(f1_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be838ba",
   "metadata": {},
   "source": [
    "# RFE feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18060549",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = X.columns.tolist() + ['bmi_class', 'life']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "871eccd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_566f2_row0_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 100.0%, transparent 100.0%);\n",
       "}\n",
       "#T_566f2_row1_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 93.5%, transparent 93.5%);\n",
       "}\n",
       "#T_566f2_row2_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 34.3%, transparent 34.3%);\n",
       "}\n",
       "#T_566f2_row3_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 22.1%, transparent 22.1%);\n",
       "}\n",
       "#T_566f2_row4_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 15.5%, transparent 15.5%);\n",
       "}\n",
       "#T_566f2_row5_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 7.7%, transparent 7.7%);\n",
       "}\n",
       "#T_566f2_row6_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 5.4%, transparent 5.4%);\n",
       "}\n",
       "#T_566f2_row7_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 3.8%, transparent 3.8%);\n",
       "}\n",
       "#T_566f2_row8_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 1.8%, transparent 1.8%);\n",
       "}\n",
       "#T_566f2_row9_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 1.6%, transparent 1.6%);\n",
       "}\n",
       "#T_566f2_row10_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 1.2%, transparent 1.2%);\n",
       "}\n",
       "#T_566f2_row11_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 1.1%, transparent 1.1%);\n",
       "}\n",
       "#T_566f2_row12_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 0.9%, transparent 0.9%);\n",
       "}\n",
       "#T_566f2_row13_col0, #T_566f2_row14_col0, #T_566f2_row15_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 0.7%, transparent 0.7%);\n",
       "}\n",
       "#T_566f2_row16_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 0.3%, transparent 0.3%);\n",
       "}\n",
       "#T_566f2_row17_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 0.1%, transparent 0.1%);\n",
       "}\n",
       "#T_566f2_row18_col0 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #d65f5f 0.0%, transparent 0.0%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_566f2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_566f2_level0_col0\" class=\"col_heading level0 col0\" >importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row0\" class=\"row_heading level0 row0\" >weight</th>\n",
       "      <td id=\"T_566f2_row0_col0\" class=\"data row0 col0\" >0.343078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row1\" class=\"row_heading level0 row1\" >bmi_class</th>\n",
       "      <td id=\"T_566f2_row1_col0\" class=\"data row1 col0\" >0.320908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row2\" class=\"row_heading level0 row2\" >gender</th>\n",
       "      <td id=\"T_566f2_row2_col0\" class=\"data row2 col0\" >0.117667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row3\" class=\"row_heading level0 row3\" >age</th>\n",
       "      <td id=\"T_566f2_row3_col0\" class=\"data row3 col0\" >0.075779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row4\" class=\"row_heading level0 row4\" >height</th>\n",
       "      <td id=\"T_566f2_row4_col0\" class=\"data row4 col0\" >0.053126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row5\" class=\"row_heading level0 row5\" >alcohol_freq</th>\n",
       "      <td id=\"T_566f2_row5_col0\" class=\"data row5 col0\" >0.026459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row6\" class=\"row_heading level0 row6\" >eat_between_meals</th>\n",
       "      <td id=\"T_566f2_row6_col0\" class=\"data row6 col0\" >0.018617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row7\" class=\"row_heading level0 row7\" >caloric_freq</th>\n",
       "      <td id=\"T_566f2_row7_col0\" class=\"data row7 col0\" >0.013175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row8\" class=\"row_heading level0 row8\" >transportation</th>\n",
       "      <td id=\"T_566f2_row8_col0\" class=\"data row8 col0\" >0.006110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row9\" class=\"row_heading level0 row9\" >meals_perday</th>\n",
       "      <td id=\"T_566f2_row9_col0\" class=\"data row9 col0\" >0.005625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row10\" class=\"row_heading level0 row10\" >veggies_freq</th>\n",
       "      <td id=\"T_566f2_row10_col0\" class=\"data row10 col0\" >0.004047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row11\" class=\"row_heading level0 row11\" >life</th>\n",
       "      <td id=\"T_566f2_row11_col0\" class=\"data row11 col0\" >0.003654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row12\" class=\"row_heading level0 row12\" >devices_perday</th>\n",
       "      <td id=\"T_566f2_row12_col0\" class=\"data row12 col0\" >0.003229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row13\" class=\"row_heading level0 row13\" >physical_activity_perweek</th>\n",
       "      <td id=\"T_566f2_row13_col0\" class=\"data row13 col0\" >0.002418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row14\" class=\"row_heading level0 row14\" >monitor_calories</th>\n",
       "      <td id=\"T_566f2_row14_col0\" class=\"data row14 col0\" >0.002351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row15\" class=\"row_heading level0 row15\" >parent_overweight</th>\n",
       "      <td id=\"T_566f2_row15_col0\" class=\"data row15 col0\" >0.002342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row16\" class=\"row_heading level0 row16\" >water_daily</th>\n",
       "      <td id=\"T_566f2_row16_col0\" class=\"data row16 col0\" >0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row17\" class=\"row_heading level0 row17\" >siblings</th>\n",
       "      <td id=\"T_566f2_row17_col0\" class=\"data row17 col0\" >0.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_566f2_level0_row18\" class=\"row_heading level0 row18\" >smoke</th>\n",
       "      <td id=\"T_566f2_row18_col0\" class=\"data row18 col0\" >0.000118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28faa2e5310>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = tree_gb.feature_importances_\n",
    "\n",
    "importances_df = pd.DataFrame(importances, index=new_columns, columns=['importance'])\n",
    "importances_df = importances_df.sort_values('importance', ascending=False)\n",
    "importances_df.style.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8a9d2c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [06:38<00:00, 26.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 16\n",
      "Highest F1 score with 16 features: 0.942469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from tqdm import tqdm\n",
    "\n",
    "nof_list = np.arange(5, len(new_columns) + 1) # start from 5 because weight, bmi, gender, age and height will definitely be inside the model based on feature importances\n",
    "high_score = float('-inf')\n",
    "nof = 0\n",
    "score_list = []\n",
    "best_features = None\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for n in tqdm(nof_list):\n",
    "    fold_scores = []\n",
    "    for train_index, val_index in skf.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        # Impute missing values using KNN impute\n",
    "        X_train_fold, X_val_fold = knn_impute(X_train_fold, X_val_fold, numerical_columns)\n",
    "\n",
    "        # Classify BMI based on age and BMI value\n",
    "        X_train_fold['bmi_class'] = X_train_fold.apply(classify_bmi_comprehensive, axis=1)\n",
    "        X_val_fold['bmi_class'] = X_val_fold.apply(classify_bmi_comprehensive, axis=1)\n",
    "\n",
    "        # Impute missing values using Iterative impute\n",
    "        X_train_fold, X_val_fold = iterative_impute(X_train_fold, X_val_fold)\n",
    "\n",
    "        # Add life feature\n",
    "        add_life_score(X_train_fold)\n",
    "        add_life_score(X_val_fold)\n",
    "\n",
    "        # Scale the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Feature selection using RFE\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        rfe = RFE(model, n_features_to_select=n)\n",
    "        X_train_rfe = rfe.fit_transform(X_train_fold, y_train_fold)\n",
    "        X_val_rfe = rfe.transform(X_val_fold)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        model.fit(X_train_rfe, y_train_fold)\n",
    "        y_pred = model.predict(X_val_rfe)\n",
    "        score = f1_score(y_val_fold, y_pred, average='macro')\n",
    "        fold_scores.append(score)\n",
    "    \n",
    "    avg_score = np.mean(fold_scores)\n",
    "    score_list.append(avg_score)\n",
    "    \n",
    "    if avg_score > high_score:\n",
    "        high_score = avg_score\n",
    "        nof = n\n",
    "        best_features = rfe.get_support()\n",
    "\n",
    "print(f\"Optimum number of features: {nof}\")\n",
    "print(f\"Highest F1 score with {nof} features: {high_score:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb00457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features with 16 features:\n",
      "['age' 'alcohol_freq' 'caloric_freq' 'devices_perday' 'eat_between_meals'\n",
      " 'gender' 'height' 'meals_perday' 'parent_overweight'\n",
      " 'physical_activity_perweek' 'transportation' 'veggies_freq' 'water_daily'\n",
      " 'weight' 'bmi_class' 'life']\n"
     ]
    }
   ],
   "source": [
    "# Filter `new_columns` with the boolean mask to get selected feature names\n",
    "selected_feature_names = np.array(new_columns)[best_features]\n",
    "print(f\"Selected features with {nof} features:\")\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f964f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_freq</th>\n",
       "      <th>caloric_freq</th>\n",
       "      <th>devices_perday</th>\n",
       "      <th>eat_between_meals</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>meals_perday</th>\n",
       "      <th>parent_overweight</th>\n",
       "      <th>physical_activity_perweek</th>\n",
       "      <th>transportation</th>\n",
       "      <th>veggies_freq</th>\n",
       "      <th>water_daily</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  alcohol_freq  caloric_freq  devices_perday  eat_between_meals  \\\n",
       "0  21.0           0.0           0.0             2.0                1.0   \n",
       "1  23.0           2.0           0.0             2.0                1.0   \n",
       "2   NaN           2.0           0.0             1.0                1.0   \n",
       "\n",
       "   gender  height  meals_perday  parent_overweight  physical_activity_perweek  \\\n",
       "0     1.0    1.62           3.0                1.0                        0.0   \n",
       "1     0.0    1.80           3.0                1.0                        4.0   \n",
       "2     0.0    1.80           3.0                0.0                        4.0   \n",
       "\n",
       "   transportation  veggies_freq  water_daily  weight  \n",
       "0             2.0           1.0          2.0    64.0  \n",
       "1             2.0           1.0          2.0    77.0  \n",
       "2             0.0           3.0          2.0    87.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it tells us to keep newly added columns like 'bmi_class' and 'life'\n",
    "# We delete 'smoke' and 'siblings'\n",
    "# Probably also caloric_frequency, monitor_calories, water_daily\n",
    "\n",
    "\n",
    "# Filter out 'bmi_class' and 'life' from selected_feature_names\n",
    "filtered_selected_features = [feature for feature in selected_feature_names if feature not in ['bmi_class', 'life']]\n",
    "\n",
    "numerical_columns = [feature for feature in numerical_columns if feature in selected_feature_names]\n",
    "\n",
    "# Create a DataFrame with only the filtered selected features\n",
    "best_selected_features_df = X_train[filtered_selected_features]\n",
    "best_selected_features_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4fbfc7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'height', 'meals_perday', 'weight']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bdcc7",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bcd9163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-12 18:56:20,905] A new study created in memory with name: no-name-0bdbbe63-57bc-451c-a30f-a68f7e0234f2\n",
      "[I 2024-11-12 18:59:09,911] Trial 14 finished with value: 0.9484582075959294 and parameters: {'n_estimators': 136, 'max_depth': 3, 'learning_rate': 0.19906019870089836, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.9476265064182218}. Best is trial 14 with value: 0.9484582075959294.\n",
      "[I 2024-11-12 19:07:08,528] Trial 8 finished with value: 0.9551483282186031 and parameters: {'n_estimators': 277, 'max_depth': 6, 'learning_rate': 0.1872538268526377, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.5361376560050419}. Best is trial 8 with value: 0.9551483282186031.\n",
      "[I 2024-11-12 19:10:00,660] Trial 15 finished with value: 0.952899267567813 and parameters: {'n_estimators': 343, 'max_depth': 13, 'learning_rate': 0.297230936323579, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7023259749838806}. Best is trial 8 with value: 0.9551483282186031.\n",
      "[I 2024-11-12 19:11:11,857] Trial 11 finished with value: 0.9548063646083402 and parameters: {'n_estimators': 453, 'max_depth': 8, 'learning_rate': 0.18369904088034117, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.6563186989796045}. Best is trial 8 with value: 0.9551483282186031.\n",
      "[I 2024-11-12 19:11:35,622] Trial 13 finished with value: 0.9524055830152169 and parameters: {'n_estimators': 404, 'max_depth': 6, 'learning_rate': 0.11227072740504018, 'min_samples_split': 9, 'min_samples_leaf': 1, 'subsample': 0.9533420566678845}. Best is trial 8 with value: 0.9551483282186031.\n",
      "[I 2024-11-12 19:15:12,743] Trial 3 finished with value: 0.9513024625703483 and parameters: {'n_estimators': 285, 'max_depth': 26, 'learning_rate': 0.269304126849752, 'min_samples_split': 9, 'min_samples_leaf': 3, 'subsample': 0.7722302414294492}. Best is trial 8 with value: 0.9551483282186031.\n",
      "[I 2024-11-12 19:15:54,810] Trial 2 finished with value: 0.9501561684525924 and parameters: {'n_estimators': 327, 'max_depth': 23, 'learning_rate': 0.23556105485439785, 'min_samples_split': 10, 'min_samples_leaf': 4, 'subsample': 0.7688344596327722}. Best is trial 8 with value: 0.9551483282186031.\n",
      "[I 2024-11-12 19:18:48,710] Trial 7 finished with value: 0.8818113851248004 and parameters: {'n_estimators': 215, 'max_depth': 22, 'learning_rate': 0.2585064221391271, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.511241016354892}. Best is trial 8 with value: 0.9551483282186031.\n",
      "[I 2024-11-12 19:18:55,337] Trial 9 finished with value: 0.9507881718120904 and parameters: {'n_estimators': 492, 'max_depth': 24, 'learning_rate': 0.28751514742837575, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.7508341176446192}. Best is trial 8 with value: 0.9551483282186031.\n",
      "[I 2024-11-12 19:19:06,528] Trial 5 finished with value: 0.9522858980737052 and parameters: {'n_estimators': 275, 'max_depth': 14, 'learning_rate': 0.18131721200129608, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.5710813382972514}. Best is trial 8 with value: 0.9551483282186031.\n",
      "[I 2024-11-12 19:23:51,539] Trial 21 finished with value: 0.955158089532617 and parameters: {'n_estimators': 453, 'max_depth': 6, 'learning_rate': 0.22432336650225948, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.8653829728806819}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:29:23,878] Trial 0 finished with value: 0.9508362852776495 and parameters: {'n_estimators': 114, 'max_depth': 16, 'learning_rate': 0.05899854341658084, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.9251041731371785}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:30:14,523] Trial 23 finished with value: 0.9510773495189783 and parameters: {'n_estimators': 390, 'max_depth': 4, 'learning_rate': 0.04968955405850557, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.9046679673963698}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:35:42,929] Trial 24 finished with value: 0.9510516943998952 and parameters: {'n_estimators': 359, 'max_depth': 10, 'learning_rate': 0.12942664299039652, 'min_samples_split': 9, 'min_samples_leaf': 3, 'subsample': 0.9059401224004364}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:38:17,115] Trial 22 finished with value: 0.9488839028518956 and parameters: {'n_estimators': 394, 'max_depth': 14, 'learning_rate': 0.1647807257739506, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.7568121593830579}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:41:57,693] Trial 17 finished with value: 0.9492969537091127 and parameters: {'n_estimators': 247, 'max_depth': 25, 'learning_rate': 0.12713151633299832, 'min_samples_split': 10, 'min_samples_leaf': 2, 'subsample': 0.9529117239556767}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:43:36,396] Trial 4 finished with value: 0.9510145558353498 and parameters: {'n_estimators': 474, 'max_depth': 19, 'learning_rate': 0.09187872627358998, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.9221174375227833}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:45:04,290] Trial 27 finished with value: 0.9531332254599999 and parameters: {'n_estimators': 391, 'max_depth': 9, 'learning_rate': 0.12867565695971325, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.8604558624718819}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:45:43,382] Trial 29 finished with value: 0.9533622307164231 and parameters: {'n_estimators': 226, 'max_depth': 10, 'learning_rate': 0.2229630968496575, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.849532874822257}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:46:18,182] Trial 28 finished with value: 0.954025794955988 and parameters: {'n_estimators': 228, 'max_depth': 10, 'learning_rate': 0.12948113144060294, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.8756991151929464}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:48:03,232] Trial 1 finished with value: 0.9497278013761686 and parameters: {'n_estimators': 401, 'max_depth': 25, 'learning_rate': 0.07930167795074751, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.977345821651086}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:48:12,680] Trial 30 finished with value: 0.9526302730352818 and parameters: {'n_estimators': 229, 'max_depth': 10, 'learning_rate': 0.22237967296549074, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.8382310965646371}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:48:15,940] Trial 18 finished with value: 0.9482666559047482 and parameters: {'n_estimators': 180, 'max_depth': 18, 'learning_rate': 0.1384237695124399, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.6106716212818106}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:48:18,923] Trial 26 finished with value: 0.9452170980654483 and parameters: {'n_estimators': 197, 'max_depth': 9, 'learning_rate': 0.01628865145691208, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.9233757377789682}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:53:35,800] Trial 32 finished with value: 0.9545735067497784 and parameters: {'n_estimators': 181, 'max_depth': 10, 'learning_rate': 0.22094441302767207, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.8373711740059062}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:56:33,249] Trial 20 finished with value: 0.9538216620515044 and parameters: {'n_estimators': 431, 'max_depth': 10, 'learning_rate': 0.038297569737459056, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.6800852597020247}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:58:34,809] Trial 31 finished with value: 0.950486148702867 and parameters: {'n_estimators': 204, 'max_depth': 19, 'learning_rate': 0.22332323571048787, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.8711878819372123}. Best is trial 21 with value: 0.955158089532617.\n",
      "[I 2024-11-12 19:58:49,605] Trial 39 finished with value: 0.9573723331855846 and parameters: {'n_estimators': 451, 'max_depth': 6, 'learning_rate': 0.19243781712423685, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.6799684110713643}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 19:59:52,480] Trial 37 finished with value: 0.9559324661246624 and parameters: {'n_estimators': 446, 'max_depth': 7, 'learning_rate': 0.1949386453701337, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.6422684355557279}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:09:42,479] Trial 35 finished with value: 0.9465274683517814 and parameters: {'n_estimators': 186, 'max_depth': 30, 'learning_rate': 0.21826826162645313, 'min_samples_split': 7, 'min_samples_leaf': 2, 'subsample': 0.6176888408701717}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:10:13,285] Trial 42 finished with value: 0.9549334729411513 and parameters: {'n_estimators': 448, 'max_depth': 6, 'learning_rate': 0.1845611992929286, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.6158886229872039}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:10:32,663] Trial 25 finished with value: 0.9418280709128976 and parameters: {'n_estimators': 156, 'max_depth': 17, 'learning_rate': 0.0034737024124483207, 'min_samples_split': 7, 'min_samples_leaf': 1, 'subsample': 0.6078008881540596}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:12:11,261] Trial 36 finished with value: 0.9483858259768209 and parameters: {'n_estimators': 448, 'max_depth': 30, 'learning_rate': 0.20124179421079097, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.6320745864928328}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:12:17,663] Trial 43 finished with value: 0.9566244041626797 and parameters: {'n_estimators': 447, 'max_depth': 6, 'learning_rate': 0.15987622154975972, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.5167256602292272}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:12:24,083] Trial 44 finished with value: 0.9537904513716047 and parameters: {'n_estimators': 439, 'max_depth': 6, 'learning_rate': 0.160026923141607, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.6429915222935684}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:14:01,799] Trial 38 finished with value: 0.9467873141760281 and parameters: {'n_estimators': 451, 'max_depth': 30, 'learning_rate': 0.19138124879410245, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.668534498493482}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:21:10,490] Trial 12 finished with value: 0.9510878759073904 and parameters: {'n_estimators': 321, 'max_depth': 16, 'learning_rate': 0.0329135868399355, 'min_samples_split': 8, 'min_samples_leaf': 2, 'subsample': 0.6399219798987372}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:22:01,948] Trial 47 finished with value: 0.9540920029941207 and parameters: {'n_estimators': 427, 'max_depth': 6, 'learning_rate': 0.25261200086539304, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.5162279326226172}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:22:18,049] Trial 50 finished with value: 0.9528539202299566 and parameters: {'n_estimators': 477, 'max_depth': 4, 'learning_rate': 0.24994674020082003, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7196778961012255}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:22:31,244] Trial 45 finished with value: 0.9547801060429881 and parameters: {'n_estimators': 440, 'max_depth': 5, 'learning_rate': 0.15984987927395847, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.7097043666482781}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:23:32,499] Trial 40 finished with value: 0.9486234991007407 and parameters: {'n_estimators': 452, 'max_depth': 29, 'learning_rate': 0.17127619917912307, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.6661749371090209}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:24:12,396] Trial 41 finished with value: 0.9509568832909296 and parameters: {'n_estimators': 468, 'max_depth': 30, 'learning_rate': 0.19287915401443606, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.6301593468651794}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:24:13,736] Trial 51 finished with value: 0.9529307731980812 and parameters: {'n_estimators': 498, 'max_depth': 4, 'learning_rate': 0.2648204138847656, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7147764094281105}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:25:16,620] Trial 49 finished with value: 0.9562000644800805 and parameters: {'n_estimators': 488, 'max_depth': 4, 'learning_rate': 0.1594940315048179, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7184885508506397}. Best is trial 39 with value: 0.9573723331855846.\n",
      "[I 2024-11-12 20:26:19,678] Trial 46 finished with value: 0.9592114637589505 and parameters: {'n_estimators': 490, 'max_depth': 6, 'learning_rate': 0.1596739283333852, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.5207615990703254}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:29:38,550] Trial 48 finished with value: 0.9535186822133888 and parameters: {'n_estimators': 494, 'max_depth': 6, 'learning_rate': 0.1576000178900099, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.5498259976377808}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:33:41,504] Trial 52 finished with value: 0.9553673036593725 and parameters: {'n_estimators': 497, 'max_depth': 4, 'learning_rate': 0.25017204868656834, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7917963893816227}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:34:48,420] Trial 53 finished with value: 0.9520505269677404 and parameters: {'n_estimators': 489, 'max_depth': 4, 'learning_rate': 0.24227034143543286, 'min_samples_split': 5, 'min_samples_leaf': 4, 'subsample': 0.7118508121390428}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:36:16,357] Trial 34 finished with value: 0.9380377367838559 and parameters: {'n_estimators': 181, 'max_depth': 30, 'learning_rate': 0.005683884321041416, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.6470497970671624}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:42:19,916] Trial 58 finished with value: 0.9515870850007392 and parameters: {'n_estimators': 304, 'max_depth': 8, 'learning_rate': 0.20795357410183085, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.5526978224557598}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:43:12,792] Trial 57 finished with value: 0.9541343526813181 and parameters: {'n_estimators': 498, 'max_depth': 8, 'learning_rate': 0.2401586917525988, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.5503521724457522}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:45:31,025] Trial 56 finished with value: 0.9528586199898129 and parameters: {'n_estimators': 477, 'max_depth': 8, 'learning_rate': 0.20613074223609967, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.5496001469552654}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:47:08,996] Trial 62 finished with value: 0.9523708468330649 and parameters: {'n_estimators': 412, 'max_depth': 3, 'learning_rate': 0.09487442184060041, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.5416702964138913}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:54:16,376] Trial 54 finished with value: 0.9539084775762067 and parameters: {'n_estimators': 496, 'max_depth': 12, 'learning_rate': 0.16672941946923245, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.7968244256566941}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:55:24,683] Trial 33 finished with value: 0.9308990024541 and parameters: {'n_estimators': 187, 'max_depth': 29, 'learning_rate': 0.003606262331416865, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.8236161852475667}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:55:26,924] Trial 59 finished with value: 0.953996261806279 and parameters: {'n_estimators': 418, 'max_depth': 8, 'learning_rate': 0.10467855744288546, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8115257109844277}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:57:24,352] Trial 67 finished with value: 0.9523533537693993 and parameters: {'n_estimators': 419, 'max_depth': 3, 'learning_rate': 0.10165704241528106, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.8082210465026821}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 20:58:46,189] Trial 66 finished with value: 0.9522206079315779 and parameters: {'n_estimators': 472, 'max_depth': 3, 'learning_rate': 0.0987157348486685, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.7885451887708342}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:00:53,099] Trial 60 finished with value: 0.9567183442568659 and parameters: {'n_estimators': 414, 'max_depth': 8, 'learning_rate': 0.10217731986700639, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.5669804511230276}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:08:23,556] Trial 68 finished with value: 0.9540489224930149 and parameters: {'n_estimators': 372, 'max_depth': 7, 'learning_rate': 0.14750769749528636, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7893751040273619}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:09:47,196] Trial 61 finished with value: 0.954926668647204 and parameters: {'n_estimators': 477, 'max_depth': 8, 'learning_rate': 0.08636948480844903, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.5821390894308592}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:10:55,552] Trial 64 finished with value: 0.9514341945338234 and parameters: {'n_estimators': 412, 'max_depth': 8, 'learning_rate': 0.10252976428918911, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.5650468244299951}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:11:30,865] Trial 71 finished with value: 0.9523908049943284 and parameters: {'n_estimators': 469, 'max_depth': 3, 'learning_rate': 0.14803173221320812, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.5761874374332361}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:15:01,634] Trial 63 finished with value: 0.9561417447495986 and parameters: {'n_estimators': 423, 'max_depth': 8, 'learning_rate': 0.0826132338522794, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.576329485361435}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:17:30,943] Trial 72 finished with value: 0.955832653737241 and parameters: {'n_estimators': 369, 'max_depth': 5, 'learning_rate': 0.14675425292540062, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.5742323495158631}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:17:43,208] Trial 69 finished with value: 0.9527978232721539 and parameters: {'n_estimators': 468, 'max_depth': 7, 'learning_rate': 0.1451731367710501, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.7865802309880943}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:19:09,817] Trial 55 finished with value: 0.9527486688552343 and parameters: {'n_estimators': 489, 'max_depth': 12, 'learning_rate': 0.0845834082129093, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.8111038115306806}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:20:31,686] Trial 70 finished with value: 0.9547417466943251 and parameters: {'n_estimators': 466, 'max_depth': 7, 'learning_rate': 0.1438268986831346, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.5767582666665432}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:28:32,950] Trial 76 finished with value: 0.9561294543568714 and parameters: {'n_estimators': 463, 'max_depth': 5, 'learning_rate': 0.14425500577094832, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.5818127001076835}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:28:42,913] Trial 78 finished with value: 0.9565430037863422 and parameters: {'n_estimators': 467, 'max_depth': 5, 'learning_rate': 0.1755301401345644, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.5075160639174853}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:29:40,686] Trial 77 finished with value: 0.9507510029038485 and parameters: {'n_estimators': 464, 'max_depth': 5, 'learning_rate': 0.14240765330407057, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.7368058905478887}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:31:46,233] Trial 73 finished with value: 0.9553637155978871 and parameters: {'n_estimators': 369, 'max_depth': 7, 'learning_rate': 0.07777795894716431, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.5047493261389583}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:33:41,802] Trial 19 finished with value: 0.9492823031789159 and parameters: {'n_estimators': 437, 'max_depth': 24, 'learning_rate': 0.044219512739946384, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.7645363513526815}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:34:11,097] Trial 74 finished with value: 0.9531951424796319 and parameters: {'n_estimators': 365, 'max_depth': 12, 'learning_rate': 0.14382211612889914, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.5864936913278513}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:34:43,522] Trial 65 finished with value: 0.9562562231015708 and parameters: {'n_estimators': 415, 'max_depth': 12, 'learning_rate': 0.09505574046255397, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.5758927653060263}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:34:52,685] Trial 10 finished with value: 0.9477665989740928 and parameters: {'n_estimators': 374, 'max_depth': 27, 'learning_rate': 0.01593808587239229, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.9634679326390407}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:36:03,581] Trial 75 finished with value: 0.955252536852304 and parameters: {'n_estimators': 464, 'max_depth': 5, 'learning_rate': 0.07682234771310081, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.5135382050772964}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:37:11,161] Trial 6 finished with value: 0.9420238059051739 and parameters: {'n_estimators': 332, 'max_depth': 20, 'learning_rate': 0.007416711171293936, 'min_samples_split': 4, 'min_samples_leaf': 4, 'subsample': 0.9107928313107105}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:42:08,715] Trial 88 finished with value: 0.9505320366702715 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.11524402908364957, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.5292650336713436}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:44:23,680] Trial 79 finished with value: 0.9573572175042795 and parameters: {'n_estimators': 462, 'max_depth': 5, 'learning_rate': 0.07187278585121236, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.5070500375635737}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:47:20,310] Trial 82 finished with value: 0.9553223559360138 and parameters: {'n_estimators': 428, 'max_depth': 5, 'learning_rate': 0.06718417357716068, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.5233511185186206}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:50:32,811] Trial 83 finished with value: 0.9546439451823622 and parameters: {'n_estimators': 435, 'max_depth': 5, 'learning_rate': 0.0743669819538071, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.5011848902639534}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:51:41,594] Trial 87 finished with value: 0.9533181444007018 and parameters: {'n_estimators': 431, 'max_depth': 5, 'learning_rate': 0.17696194382439076, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.5235862318275883}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 21:57:28,259] Trial 89 finished with value: 0.9539428960801871 and parameters: {'n_estimators': 459, 'max_depth': 5, 'learning_rate': 0.17407283326301703, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.5242542896371022}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:02:11,101] Trial 84 finished with value: 0.9560327639427374 and parameters: {'n_estimators': 429, 'max_depth': 5, 'learning_rate': 0.06937259576587886, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.5060009927124155}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:02:23,821] Trial 86 finished with value: 0.9533012995785617 and parameters: {'n_estimators': 433, 'max_depth': 5, 'learning_rate': 0.0669778351857853, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.5053439824974522}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:10:56,860] Trial 94 finished with value: 0.9541123588449958 and parameters: {'n_estimators': 386, 'max_depth': 9, 'learning_rate': 0.176649060202389, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.5987627101311146}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:11:56,338] Trial 93 finished with value: 0.9540349904943547 and parameters: {'n_estimators': 399, 'max_depth': 9, 'learning_rate': 0.11765086260804361, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.526519195505478}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:13:24,486] Trial 96 finished with value: 0.9509165078370565 and parameters: {'n_estimators': 402, 'max_depth': 9, 'learning_rate': 0.1744896193477321, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.5024823507413365}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:14:41,957] Trial 97 finished with value: 0.9561517867466172 and parameters: {'n_estimators': 351, 'max_depth': 9, 'learning_rate': 0.17633827783101824, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.5965880568276941}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:19:03,852] Trial 81 finished with value: 0.9522865719972172 and parameters: {'n_estimators': 428, 'max_depth': 11, 'learning_rate': 0.0689766615957807, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.5057750509141874}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:19:46,468] Trial 80 finished with value: 0.9505373265900776 and parameters: {'n_estimators': 463, 'max_depth': 11, 'learning_rate': 0.06826711605844386, 'min_samples_split': 3, 'min_samples_leaf': 3, 'subsample': 0.5046571202759793}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:22:43,494] Trial 92 finished with value: 0.9540389689487017 and parameters: {'n_estimators': 397, 'max_depth': 9, 'learning_rate': 0.06514844153672394, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.5268730956812477}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:23:30,777] Trial 91 finished with value: 0.951699607684277 and parameters: {'n_estimators': 399, 'max_depth': 9, 'learning_rate': 0.07187174050556787, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.5216675220284686}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:24:39,141] Trial 85 finished with value: 0.9519979163672788 and parameters: {'n_estimators': 433, 'max_depth': 11, 'learning_rate': 0.06872664033352897, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.5003074301352005}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:26:25,588] Trial 16 finished with value: 0.9499397991066788 and parameters: {'n_estimators': 438, 'max_depth': 21, 'learning_rate': 0.01951543719086241, 'min_samples_split': 9, 'min_samples_leaf': 1, 'subsample': 0.7980162758854963}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:28:48,101] Trial 98 finished with value: 0.9554871536032528 and parameters: {'n_estimators': 397, 'max_depth': 9, 'learning_rate': 0.05730946480018784, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.6838206082808557}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:28:55,127] Trial 90 finished with value: 0.9503138771817348 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.06548466328701019, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.5229469654242629}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:29:28,798] Trial 99 finished with value: 0.9586657532041649 and parameters: {'n_estimators': 386, 'max_depth': 9, 'learning_rate': 0.05502457036145774, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.6948677159261646}. Best is trial 46 with value: 0.9592114637589505.\n",
      "[I 2024-11-12 22:31:00,670] Trial 95 finished with value: 0.9478815153287355 and parameters: {'n_estimators': 395, 'max_depth': 15, 'learning_rate': 0.06478953921543013, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.5298820773909746}. Best is trial 46 with value: 0.9592114637589505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 490, 'max_depth': 6, 'learning_rate': 0.1596739283333852, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.5207615990703254}\n"
     ]
    }
   ],
   "source": [
    "y_train_encoded = y_train.copy()\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest values for hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 30)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.3)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "        \n",
    "    # Initialize GradientBoostingClassifier with suggested hyperparameters\n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        subsample=subsample\n",
    "    )\n",
    "    \n",
    "    # Initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, val_index in skf.split(best_selected_features_df, y_train_encoded):\n",
    "        X_train_fold, X_val_fold = best_selected_features_df.iloc[train_index], best_selected_features_df.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_encoded[train_index], y_train_encoded[val_index]\n",
    "        \n",
    "        # Impute missing values using KNN impute\n",
    "        X_train_fold, X_val_fold = knn_impute(X_train_fold, X_val_fold, numerical_columns)\n",
    "\n",
    "        # Classify BMI based on age and BMI value\n",
    "        X_train_fold['bmi_class'] = X_train_fold.apply(classify_bmi_comprehensive, axis=1)\n",
    "        X_val_fold['bmi_class'] = X_val_fold.apply(classify_bmi_comprehensive, axis=1)\n",
    "\n",
    "        # Impute missing values using Iterative impute\n",
    "        X_train_fold, X_val_fold = iterative_impute(X_train_fold, X_val_fold)\n",
    "\n",
    "        # Add life feature\n",
    "        add_life_score(X_train_fold)\n",
    "        add_life_score(X_val_fold)\n",
    "\n",
    "        # Initialize the scaler\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Fit the scaler on the training fold and transform both training and validation folds\n",
    "        X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Fit the model on the training fold\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predict on the validation fold\n",
    "        y_pred_fold = model.predict(X_val_fold)\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(y_val_fold, y_pred_fold, average='macro')\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# Set up Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "\n",
    "# Retrieve the best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42bd60bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Parameters: {'n_estimators': 490, 'max_depth': 6, 'learning_rate': 0.1596739283333852, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.5207615990703254}\n",
    "# ---- !!! DO NOT DELETE FOR ANY REASON !!! ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e072080",
   "metadata": {},
   "source": [
    "Lets re-train our model based on the tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970dc8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 490,\n",
       " 'max_depth': 6,\n",
       " 'learning_rate': 0.1596739283333852,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'subsample': 0.5207615990703254}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params =  {'n_estimators': 490, 'max_depth': 6, 'learning_rate': 0.1596739283333852, 'min_samples_split': 2, 'min_samples_leaf': 4, 'subsample': 0.5207615990703254}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f60f6d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.9510421339996504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Gradient Boosting model\n",
    "tree_gb = GradientBoostingClassifier(**best_params)\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Stratified K-Fold Cross Validation\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Impute missing values using KNN impute\n",
    "    X_train_fold, X_val_fold = knn_impute(X_train_fold, X_val_fold, numerical_columns)\n",
    "\n",
    "    # Classify BMI based on age and BMI value\n",
    "    X_train_fold['bmi_class'] = X_train_fold.apply(lambda row: classify_bmi_comprehensive(row), axis=1)\n",
    "    X_val_fold['bmi_class'] = X_val_fold.apply(lambda row: classify_bmi_comprehensive(row), axis=1)\n",
    "\n",
    "    # Impute missing values using Iterative impute\n",
    "    X_train_fold, X_val_fold = iterative_impute(X_train_fold, X_val_fold)\n",
    "\n",
    "    # Add life feature\n",
    "    add_life_score(X_train_fold)\n",
    "    add_life_score(X_val_fold)\n",
    "    \n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler on the training fold and transform both training and validation folds\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "\n",
    "    # Fit the model on the training fold\n",
    "    tree_gb.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_pred_fold = tree_gb.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_val_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print the average F1 score\n",
    "print(f\"Average F1 Score: {np.mean(f1_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d1e3a1",
   "metadata": {
    "id": "14d1e3a1"
   },
   "source": [
    "<a class=\"anchor\" id=\"\">\n",
    "\n",
    "# 4 & 5. Model & Assess (Modelling and Assessment)\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad01ff7",
   "metadata": {
    "id": "7ad01ff7"
   },
   "source": [
    "<img src=\"image/step4.png\" style=\"height:60px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89849818",
   "metadata": {
    "id": "89849818"
   },
   "source": [
    "### 4.1. Model Selection\n",
    "\n",
    "In this section you should take the time to train different predictive algorithms with the data that got to this stage and **use the approppriate model assessment metrics to decide which model you think is the best to address your problem**.\n",
    "\n",
    "**You are expected to present on your report the model performances of the different algorithms that you tested and discuss what informed your choice for a specific algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92285396",
   "metadata": {
    "id": "92285396"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f08f9c24",
   "metadata": {
    "id": "f08f9c24"
   },
   "source": [
    "### 4.2. Model Optimization\n",
    "\n",
    "After selecting the best algorithm (set of algorithms), you can try to optimize the performance of your model by fiddling with the algorithms' hyper-parameters and select the options that result on the best overall performance.\n",
    "\n",
    "Possible ways of doing this can be through:\n",
    "1. [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "2. [RandomSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "**While you are not required to show the results of all combinations of hyperparameters that you tried, you should at least discuss the what were the possible combinations used and which of them resulted in your best performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387961a5",
   "metadata": {
    "id": "387961a5",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebfaed02",
   "metadata": {
    "id": "ebfaed02"
   },
   "source": [
    "<a class=\"anchor\" id=\"\">\n",
    "\n",
    "# 5. Deploy\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24677b",
   "metadata": {
    "id": "dc24677b"
   },
   "source": [
    "<img src=\"image/step5.png\" style=\"height:60px\">\n",
    "\n",
    "### 5.0 Training a final model\n",
    "\n",
    "You used the previous steps of modelling and assessment to determine what would be best strategies when it comes to preprocessing, scaling, feature selection, algorithm and hyper-parameters you could find.\n",
    "\n",
    "**By this stage, all of those choices were already made**. For that reason, a split between training and validation is no longer necessary. **A good practice** would be to take the initial data and train a final model with all of the labeled data that you have available.\n",
    "\n",
    "**Everything is figured by this stage**, so, on a first level all you need to do is replicate the exact preprocessing, scaling and feature selection decisions you made before.<br>\n",
    "When it comes to the final model, all you have to do is creeate a new instance of your best algorithm with the best parameters that you uncovered (no need to try all algorithms and hyper-parameters again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ebbfc",
   "metadata": {
    "id": "191ebbfc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f38b4acc",
   "metadata": {
    "id": "f38b4acc"
   },
   "source": [
    "### 5.1. Import and Transform your test data\n",
    "\n",
    "Remember, the test data does not have the `outcome` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2b0991fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2bb00d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = pd.read_csv(\"../data/obesity_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2830c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually encode data\n",
    "\n",
    "columns = ['alcohol_freq',\n",
    " 'caloric_freq',\n",
    " 'devices_perday',\n",
    " 'eat_between_meals',\n",
    " 'gender',\n",
    " 'monitor_calories',\n",
    " 'parent_overweight',\n",
    " 'physical_activity_perweek',\n",
    " 'smoke',\n",
    " 'transportation',\n",
    " 'veggies_freq',\n",
    " 'water_daily',\n",
    " 'meals_perday',\n",
    " \"siblings\"]\n",
    "\n",
    "for target in columns:\n",
    "    to_predict[target] = to_predict[target].replace(hashmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9e92f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = to_predict.drop(columns=['marrital_status', 'region', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3a542cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_gb = GradientBoostingClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf433a",
   "metadata": {
    "id": "4dbf433a"
   },
   "outputs": [],
   "source": [
    "# Impute missing values using KNN impute\n",
    "\n",
    "X_train, to_predict = knn_impute(X_train, to_predict, numerical_columns)\n",
    "\n",
    "# Classify BMI based on age and BMI value\n",
    "X_train['bmi_class'] = X_train.apply(classify_bmi_comprehensive, axis=1)\n",
    "to_predict['bmi_class'] = to_predict.apply(classify_bmi_comprehensive, axis=1)\n",
    "\n",
    "# Impute missing values using Iterative impute\n",
    "X_train, to_predict = iterative_impute(X_train, to_predict)\n",
    "\n",
    "# Add life feature\n",
    "add_life_score(X_train)\n",
    "add_life_score(to_predict)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training fold and transform both training and validation folds\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "to_predict = scaler.transform(to_predict)\n",
    "\n",
    "# Fit the model on the training fold\n",
    "tree_gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation fold\n",
    "y_hat = tree_gb.predict(to_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5bdc113c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 4, 1, 4, 1, 3, 4, 3, 1, 2, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
       "       3, 3, 1, 3, 1, 1, 1, 2, 3, 1, 3, 2, 1, 2, 1, 1, 5, 3, 1, 1, 5, 4,\n",
       "       2, 4, 4, 7, 4, 1, 1, 2, 1, 1, 6, 3, 2, 5, 2, 3, 3, 1, 1, 4, 2, 1,\n",
       "       1, 3, 5, 5, 1, 4, 2, 1, 5, 1, 5, 1, 1, 1, 1, 5, 1, 5, 4, 1, 1, 4,\n",
       "       1, 1, 1, 5, 1, 5, 5, 3, 1, 3, 3, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1,\n",
       "       2, 4, 1, 1, 2, 1, 1, 1, 4, 1, 1, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6,\n",
       "       6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 4, 6, 6, 4, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], dtype=int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a27f68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert to categories\n",
    "hash_obesity_inverted = {\n",
    " 1: 'Normal_Weight',\n",
    " 2: 'Overweight_Level_I',\n",
    " 3:'Overweight_Level_II',\n",
    " 4:'Obesity_Type_I',\n",
    " 5:'Insufficient_Weight',\n",
    " 6:'Obesity_Type_II',\n",
    " 7: 'Obesity_Type_III'\n",
    " }\n",
    "y_hat_official = np.array([hash_obesity_inverted[x] for x in y_hat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b384b720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal_Weight', 'Normal_Weight', 'Obesity_Type_I',\n",
       "       'Normal_Weight', 'Obesity_Type_I', 'Normal_Weight',\n",
       "       'Overweight_Level_II', 'Obesity_Type_I', 'Overweight_Level_II',\n",
       "       'Normal_Weight', 'Overweight_Level_I', 'Overweight_Level_II',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Overweight_Level_II',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Normal_Weight', 'Normal_Weight',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Normal_Weight',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II', 'Normal_Weight',\n",
       "       'Overweight_Level_II', 'Normal_Weight', 'Normal_Weight',\n",
       "       'Normal_Weight', 'Overweight_Level_I', 'Overweight_Level_II',\n",
       "       'Normal_Weight', 'Overweight_Level_II', 'Overweight_Level_I',\n",
       "       'Normal_Weight', 'Overweight_Level_I', 'Normal_Weight',\n",
       "       'Normal_Weight', 'Insufficient_Weight', 'Overweight_Level_II',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Insufficient_Weight',\n",
       "       'Obesity_Type_I', 'Overweight_Level_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_III', 'Obesity_Type_I',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Overweight_Level_I',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Obesity_Type_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_I', 'Insufficient_Weight',\n",
       "       'Overweight_Level_I', 'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Obesity_Type_I',\n",
       "       'Overweight_Level_I', 'Normal_Weight', 'Normal_Weight',\n",
       "       'Overweight_Level_II', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Normal_Weight', 'Obesity_Type_I',\n",
       "       'Overweight_Level_I', 'Normal_Weight', 'Insufficient_Weight',\n",
       "       'Normal_Weight', 'Insufficient_Weight', 'Normal_Weight',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Normal_Weight',\n",
       "       'Insufficient_Weight', 'Normal_Weight', 'Insufficient_Weight',\n",
       "       'Obesity_Type_I', 'Normal_Weight', 'Normal_Weight',\n",
       "       'Obesity_Type_I', 'Normal_Weight', 'Normal_Weight',\n",
       "       'Normal_Weight', 'Insufficient_Weight', 'Normal_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Overweight_Level_II', 'Normal_Weight', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Normal_Weight', 'Normal_Weight',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Normal_Weight',\n",
       "       'Insufficient_Weight', 'Normal_Weight', 'Normal_Weight',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Normal_Weight',\n",
       "       'Overweight_Level_I', 'Obesity_Type_I', 'Normal_Weight',\n",
       "       'Normal_Weight', 'Overweight_Level_I', 'Normal_Weight',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Obesity_Type_I',\n",
       "       'Normal_Weight', 'Normal_Weight', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight', 'Normal_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Normal_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight', 'Normal_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Insufficient_Weight',\n",
       "       'Insufficient_Weight', 'Normal_Weight', 'Insufficient_Weight',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Normal_Weight',\n",
       "       'Normal_Weight', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Normal_Weight',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Normal_Weight',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Normal_Weight',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_I', 'Overweight_Level_I', 'Overweight_Level_I',\n",
       "       'Overweight_Level_II', 'Overweight_Level_I', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Obesity_Type_I', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Normal_Weight', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Overweight_Level_II',\n",
       "       'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_II',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_I',\n",
       "       'Obesity_Type_I', 'Obesity_Type_I', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_I',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_I',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_II', 'Obesity_Type_II', 'Obesity_Type_II',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_I', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III', 'Obesity_Type_III',\n",
       "       'Obesity_Type_III', 'Obesity_Type_III'], dtype='<U19')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "17e8a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict_id = pd.read_csv(\"../data/obesity_test.csv\")['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "28953f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = pd.DataFrame(y_hat_official)\n",
    "xi.columns = ['obese_level']\n",
    "xi['id'] = to_predict_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d1efe180",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = xi[['id', 'obese_level']]\n",
    "xi.to_csv(\"../submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30624f3a",
   "metadata": {
    "id": "30624f3a"
   },
   "source": [
    "### 5.2. Obtain Predictions on the test data from your final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abdf5b3",
   "metadata": {
    "id": "6abdf5b3",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27d4b2b2",
   "metadata": {
    "id": "27d4b2b2"
   },
   "source": [
    "### 5.3. Create a Dataframe containing the index of each row and its intended prediction and export it to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c3404",
   "metadata": {
    "id": "208c3404"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95e385c2",
   "metadata": {
    "id": "95e385c2"
   },
   "source": [
    "Submit the csv file to Kaggle to obtain the model performance of your model on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b7c4e",
   "metadata": {},
   "source": [
    "# ** OTHER **\n",
    "EXhaustive search try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b8116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9aba9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Combine the must-have features with other features and scale them in each fold to avoid leakage\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Track progress with tqdm\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mcolumns)) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Fit the feature selector on the dataset that includes both must-have and other features\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     efs \u001b[38;5;241m=\u001b[39m efs\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     21\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Get the best feature subset found by the selector, which includes combinations of other features and must-have features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\mlxtend\\feature_selection\\exhaustive_feature_selector.py:443\u001b[0m, in \u001b[0;36mExhaustiveFeatureSelector.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    440\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, all_comb)\n\u001b[0;32m    441\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, pre_dispatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch)\n\u001b[0;32m    442\u001b[0m work \u001b[38;5;241m=\u001b[39m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m--> 443\u001b[0m     parallel(\n\u001b[0;32m    444\u001b[0m         delayed(_calc_score)(\n\u001b[0;32m    445\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    446\u001b[0m             X_,\n\u001b[0;32m    447\u001b[0m             y,\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(c)\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_features_group_set)),\n\u001b[0;32m    449\u001b[0m             groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    450\u001b[0m             feature_groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_groups,\n\u001b[0;32m    451\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params,\n\u001b[0;32m    452\u001b[0m         )\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m candidates\n\u001b[0;32m    454\u001b[0m     )\n\u001b[0;32m    455\u001b[0m )\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration, (indices, cv_scores) \u001b[38;5;129;01min\u001b[39;00m work:\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up the exhaustive feature selector, where 'other_features' will vary while 'must_have_features' remain\n",
    "efs = ExhaustiveFeatureSelector(\n",
    "    estimator=model,\n",
    "    min_features=6,  # Start with at least 6 features\n",
    "    max_features=len(X_train.columns),  # Consider up to all features\n",
    "    scoring='f1_macro',\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Combine the must-have features with other features and scale them in each fold to avoid leakage\n",
    "# Track progress with tqdm\n",
    "with tqdm(total=len(X_train.columns)) as progress_bar:\n",
    "    # Fit the feature selector on the dataset that includes both must-have and other features\n",
    "    efs = efs.fit(X_train, y_train)\n",
    "    progress_bar.update(len(X_train.columns))\n",
    "\n",
    "# Get the best feature subset found by the selector, which includes combinations of other features and must-have features\n",
    "selected_features = list(efs.best_feature_names_)\n",
    "\n",
    "# Perform cross-validation on the final selected features with scaling in each fold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in skf.split(X_train[final_features], y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index][final_features], X_train.iloc[val_index][final_features]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Initialize and fit the scaler only on the training data within each fold to avoid leakage\n",
    "    scaler = StandardScaler()\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Make predictions and calculate the F1 score\n",
    "    y_pred_fold = model.predict(X_val_fold)\n",
    "    f1 = f1_score(y_val_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average F1 Score after final evaluation: {np.mean(f1_scores)}\")\n",
    "print(\"Selected features including must-haves:\", final_features)\n",
    "print(\"Best F1 macro score from feature selection:\", efs.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419e9db",
   "metadata": {},
   "source": [
    "# More interpretation stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "12cc6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6e13479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9b7e16f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = knn_impute(X_train, X_test, numerical_columns)\n",
    "\n",
    "# Classify BMI based on age and BMI value\n",
    "X_train['bmi_class'] = X_train.apply(classify_bmi_comprehensive, axis=1)\n",
    "X_test['bmi_class'] = X_test.apply(classify_bmi_comprehensive, axis=1)\n",
    "\n",
    "# Impute missing values using Iterative impute\n",
    "X_train, X_test = iterative_impute(X_train, X_test)\n",
    "\n",
    "# Add life feature\n",
    "add_life_score(X_train)\n",
    "add_life_score(X_test)\n",
    "\n",
    "cols = X_train.columns \n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training fold and transform both training and validation folds\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90130d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_freq</th>\n",
       "      <th>caloric_freq</th>\n",
       "      <th>devices_perday</th>\n",
       "      <th>eat_between_meals</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>meals_perday</th>\n",
       "      <th>monitor_calories</th>\n",
       "      <th>parent_overweight</th>\n",
       "      <th>physical_activity_perweek</th>\n",
       "      <th>siblings</th>\n",
       "      <th>smoke</th>\n",
       "      <th>transportation</th>\n",
       "      <th>veggies_freq</th>\n",
       "      <th>water_daily</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi_class</th>\n",
       "      <th>life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905858</td>\n",
       "      <td>0.517302</td>\n",
       "      <td>0.366014</td>\n",
       "      <td>0.493501</td>\n",
       "      <td>-0.279560</td>\n",
       "      <td>-0.973378</td>\n",
       "      <td>0.628677</td>\n",
       "      <td>0.387140</td>\n",
       "      <td>-0.227726</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>0.064449</td>\n",
       "      <td>1.324639</td>\n",
       "      <td>-0.147862</td>\n",
       "      <td>1.522372</td>\n",
       "      <td>-0.847439</td>\n",
       "      <td>-0.006746</td>\n",
       "      <td>1.215907</td>\n",
       "      <td>0.987964</td>\n",
       "      <td>0.233931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743271</td>\n",
       "      <td>0.517302</td>\n",
       "      <td>0.366014</td>\n",
       "      <td>1.963068</td>\n",
       "      <td>-0.279560</td>\n",
       "      <td>-0.973378</td>\n",
       "      <td>0.735302</td>\n",
       "      <td>0.387140</td>\n",
       "      <td>-0.227726</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>1.258987</td>\n",
       "      <td>-1.320537</td>\n",
       "      <td>-0.147862</td>\n",
       "      <td>1.522372</td>\n",
       "      <td>1.019358</td>\n",
       "      <td>-1.457199</td>\n",
       "      <td>0.866459</td>\n",
       "      <td>0.251444</td>\n",
       "      <td>1.927367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.361101</td>\n",
       "      <td>0.517302</td>\n",
       "      <td>0.366014</td>\n",
       "      <td>-0.976066</td>\n",
       "      <td>-0.279560</td>\n",
       "      <td>1.027351</td>\n",
       "      <td>-2.143558</td>\n",
       "      <td>0.387140</td>\n",
       "      <td>-0.227726</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>-1.130088</td>\n",
       "      <td>-0.438812</td>\n",
       "      <td>-0.147862</td>\n",
       "      <td>1.522372</td>\n",
       "      <td>-0.847439</td>\n",
       "      <td>-1.457199</td>\n",
       "      <td>-0.453680</td>\n",
       "      <td>0.251444</td>\n",
       "      <td>-1.459506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.231032</td>\n",
       "      <td>-1.475887</td>\n",
       "      <td>0.366014</td>\n",
       "      <td>-0.976066</td>\n",
       "      <td>1.980041</td>\n",
       "      <td>1.027351</td>\n",
       "      <td>-0.650816</td>\n",
       "      <td>0.387140</td>\n",
       "      <td>-0.227726</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>0.064449</td>\n",
       "      <td>0.442913</td>\n",
       "      <td>-0.147862</td>\n",
       "      <td>-0.293999</td>\n",
       "      <td>1.019358</td>\n",
       "      <td>1.443707</td>\n",
       "      <td>-1.540853</td>\n",
       "      <td>-1.958115</td>\n",
       "      <td>0.657290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.207770</td>\n",
       "      <td>-1.475887</td>\n",
       "      <td>0.366014</td>\n",
       "      <td>0.493501</td>\n",
       "      <td>-0.279560</td>\n",
       "      <td>-0.973378</td>\n",
       "      <td>0.841926</td>\n",
       "      <td>1.633173</td>\n",
       "      <td>-0.227726</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>1.258987</td>\n",
       "      <td>1.324639</td>\n",
       "      <td>-0.147862</td>\n",
       "      <td>1.522372</td>\n",
       "      <td>-0.847439</td>\n",
       "      <td>-0.006746</td>\n",
       "      <td>-1.191404</td>\n",
       "      <td>-1.221595</td>\n",
       "      <td>0.657290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>3.182073</td>\n",
       "      <td>-1.475887</td>\n",
       "      <td>-2.732136</td>\n",
       "      <td>-0.976066</td>\n",
       "      <td>-0.279560</td>\n",
       "      <td>-0.973378</td>\n",
       "      <td>-1.077313</td>\n",
       "      <td>0.387140</td>\n",
       "      <td>-0.227726</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>-1.130088</td>\n",
       "      <td>0.442913</td>\n",
       "      <td>6.763071</td>\n",
       "      <td>1.522372</td>\n",
       "      <td>-0.847439</td>\n",
       "      <td>1.443707</td>\n",
       "      <td>-0.259542</td>\n",
       "      <td>0.251444</td>\n",
       "      <td>-1.036147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>-0.394836</td>\n",
       "      <td>0.517302</td>\n",
       "      <td>0.366014</td>\n",
       "      <td>0.493501</td>\n",
       "      <td>-0.279560</td>\n",
       "      <td>1.027351</td>\n",
       "      <td>1.055175</td>\n",
       "      <td>0.387140</td>\n",
       "      <td>-0.227726</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>-1.130088</td>\n",
       "      <td>-1.320537</td>\n",
       "      <td>-0.147862</td>\n",
       "      <td>-0.293999</td>\n",
       "      <td>1.019358</td>\n",
       "      <td>-0.006746</td>\n",
       "      <td>2.885494</td>\n",
       "      <td>1.724484</td>\n",
       "      <td>-0.189429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>0.905858</td>\n",
       "      <td>0.517302</td>\n",
       "      <td>0.366014</td>\n",
       "      <td>1.963068</td>\n",
       "      <td>-0.279560</td>\n",
       "      <td>-0.973378</td>\n",
       "      <td>1.375048</td>\n",
       "      <td>0.387140</td>\n",
       "      <td>-0.227726</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>0.064449</td>\n",
       "      <td>-1.320537</td>\n",
       "      <td>-0.147862</td>\n",
       "      <td>1.522372</td>\n",
       "      <td>-0.847439</td>\n",
       "      <td>-0.006746</td>\n",
       "      <td>0.866459</td>\n",
       "      <td>0.251444</td>\n",
       "      <td>0.657290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>2.369139</td>\n",
       "      <td>0.517302</td>\n",
       "      <td>0.366014</td>\n",
       "      <td>-0.976066</td>\n",
       "      <td>1.980041</td>\n",
       "      <td>1.027351</td>\n",
       "      <td>-0.544191</td>\n",
       "      <td>1.633173</td>\n",
       "      <td>-0.227726</td>\n",
       "      <td>-2.047739</td>\n",
       "      <td>-1.130088</td>\n",
       "      <td>1.324639</td>\n",
       "      <td>-0.147862</td>\n",
       "      <td>-0.293999</td>\n",
       "      <td>1.019358</td>\n",
       "      <td>-0.006746</td>\n",
       "      <td>-1.424370</td>\n",
       "      <td>-1.958115</td>\n",
       "      <td>-0.189429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>-1.045183</td>\n",
       "      <td>0.517302</td>\n",
       "      <td>0.366014</td>\n",
       "      <td>-0.976066</td>\n",
       "      <td>-0.279560</td>\n",
       "      <td>-0.973378</td>\n",
       "      <td>0.522053</td>\n",
       "      <td>0.387140</td>\n",
       "      <td>-0.227726</td>\n",
       "      <td>0.488343</td>\n",
       "      <td>0.064449</td>\n",
       "      <td>0.442913</td>\n",
       "      <td>-0.147862</td>\n",
       "      <td>-0.293999</td>\n",
       "      <td>1.019358</td>\n",
       "      <td>1.443707</td>\n",
       "      <td>0.509245</td>\n",
       "      <td>0.251444</td>\n",
       "      <td>0.657290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1075 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  alcohol_freq  caloric_freq  devices_perday  eat_between_meals  \\\n",
       "0     0.905858      0.517302      0.366014        0.493501          -0.279560   \n",
       "1     0.743271      0.517302      0.366014        1.963068          -0.279560   \n",
       "2     1.361101      0.517302      0.366014       -0.976066          -0.279560   \n",
       "3     1.231032     -1.475887      0.366014       -0.976066           1.980041   \n",
       "4    -1.207770     -1.475887      0.366014        0.493501          -0.279560   \n",
       "...        ...           ...           ...             ...                ...   \n",
       "1070  3.182073     -1.475887     -2.732136       -0.976066          -0.279560   \n",
       "1071 -0.394836      0.517302      0.366014        0.493501          -0.279560   \n",
       "1072  0.905858      0.517302      0.366014        1.963068          -0.279560   \n",
       "1073  2.369139      0.517302      0.366014       -0.976066           1.980041   \n",
       "1074 -1.045183      0.517302      0.366014       -0.976066          -0.279560   \n",
       "\n",
       "        gender    height  meals_perday  monitor_calories  parent_overweight  \\\n",
       "0    -0.973378  0.628677      0.387140         -0.227726           0.488343   \n",
       "1    -0.973378  0.735302      0.387140         -0.227726           0.488343   \n",
       "2     1.027351 -2.143558      0.387140         -0.227726           0.488343   \n",
       "3     1.027351 -0.650816      0.387140         -0.227726           0.488343   \n",
       "4    -0.973378  0.841926      1.633173         -0.227726           0.488343   \n",
       "...        ...       ...           ...               ...                ...   \n",
       "1070 -0.973378 -1.077313      0.387140         -0.227726           0.488343   \n",
       "1071  1.027351  1.055175      0.387140         -0.227726           0.488343   \n",
       "1072 -0.973378  1.375048      0.387140         -0.227726           0.488343   \n",
       "1073  1.027351 -0.544191      1.633173         -0.227726          -2.047739   \n",
       "1074 -0.973378  0.522053      0.387140         -0.227726           0.488343   \n",
       "\n",
       "      physical_activity_perweek  siblings     smoke  transportation  \\\n",
       "0                      0.064449  1.324639 -0.147862        1.522372   \n",
       "1                      1.258987 -1.320537 -0.147862        1.522372   \n",
       "2                     -1.130088 -0.438812 -0.147862        1.522372   \n",
       "3                      0.064449  0.442913 -0.147862       -0.293999   \n",
       "4                      1.258987  1.324639 -0.147862        1.522372   \n",
       "...                         ...       ...       ...             ...   \n",
       "1070                  -1.130088  0.442913  6.763071        1.522372   \n",
       "1071                  -1.130088 -1.320537 -0.147862       -0.293999   \n",
       "1072                   0.064449 -1.320537 -0.147862        1.522372   \n",
       "1073                  -1.130088  1.324639 -0.147862       -0.293999   \n",
       "1074                   0.064449  0.442913 -0.147862       -0.293999   \n",
       "\n",
       "      veggies_freq  water_daily    weight  bmi_class      life  \n",
       "0        -0.847439    -0.006746  1.215907   0.987964  0.233931  \n",
       "1         1.019358    -1.457199  0.866459   0.251444  1.927367  \n",
       "2        -0.847439    -1.457199 -0.453680   0.251444 -1.459506  \n",
       "3         1.019358     1.443707 -1.540853  -1.958115  0.657290  \n",
       "4        -0.847439    -0.006746 -1.191404  -1.221595  0.657290  \n",
       "...            ...          ...       ...        ...       ...  \n",
       "1070     -0.847439     1.443707 -0.259542   0.251444 -1.036147  \n",
       "1071      1.019358    -0.006746  2.885494   1.724484 -0.189429  \n",
       "1072     -0.847439    -0.006746  0.866459   0.251444  0.657290  \n",
       "1073      1.019358    -0.006746 -1.424370  -1.958115 -0.189429  \n",
       "1074      1.019358     1.443707  0.509245   0.251444  0.657290  \n",
       "\n",
       "[1075 rows x 19 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=cols)\n",
    "X_test = pd.DataFrame(X_test, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfe8e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 530 but corresponding boolean dimension is 160",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[173], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#plot_feature_importances(rf, X_test, y_test, 'All test data', ax=axes[0])\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,C \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(z):\n\u001b[1;32m---> 19\u001b[0m     plot_feature_importances(rf, X_test[y_pred \u001b[38;5;241m==\u001b[39m C], y_test[y_pred \u001b[38;5;241m==\u001b[39m C], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, axes[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, C)\n\u001b[0;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 530 but corresponding boolean dimension is 160"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x5000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "rf = tree_gb\n",
    "\n",
    "def plot_feature_importances(model, x, y, title, ax):\n",
    "    result = permutation_importance(model, x, y, n_repeats=5)\n",
    "    df = pd.DataFrame({'feature_name': X.columns, 'feature_importance': result.importances_mean, 'feature_std': result.importances_std})\n",
    "    sns.barplot(data=df, x='feature_importance', y='feature_name',errorbar=\"ci\", ci=\"sd\", ax=ax)\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "z = np.unique(y_pred)\n",
    "fig, axes = plt.subplots(len(z)+1,1, figsize=(8, 50))\n",
    "plot_feature_importances(rf, X_test, y_test, 'All test data', ax=axes[0])\n",
    "\n",
    "for i,C in enumerate(z):\n",
    "    plot_feature_importances(rf, X_test[y_pred == C], y_test[y_pred == C], f'Predicted as {C}', axes[i+1])\n",
    "    print(i+1, C)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3c58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
